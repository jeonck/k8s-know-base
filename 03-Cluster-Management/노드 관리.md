# ë…¸ë“œ ê´€ë¦¬

## ğŸ¯ ê°œìš”

ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì›Œì»¤ ë…¸ë“œì™€ ë§ˆìŠ¤í„° ë…¸ë“œì˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬, ë¦¬ì†ŒìŠ¤ ìµœì í™”, ë¬¸ì œ í•´ê²° ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì˜¨í”„ë ˜ í™˜ê²½ì—ì„œì˜ ì‹¤ì „ ë…¸ë“œ ìš´ì˜ ê²½í—˜ì„ ê³µìœ í•©ë‹ˆë‹¤.

## ğŸ–¥ï¸ ë…¸ë“œ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

### ë…¸ë“œ ìƒíƒœ ì´í•´

```bash
# ë…¸ë“œ ìƒíƒœ í™•ì¸
kubectl get nodes -o wide

# ë…¸ë“œ ìƒì„¸ ì •ë³´
kubectl describe node <node-name>

# ë…¸ë“œ ìƒíƒœë³„ ì˜ë¯¸
# Ready: ë…¸ë“œê°€ Podë¥¼ ë°›ì„ ì¤€ë¹„ê°€ ë¨
# NotReady: ë…¸ë“œì— ë¬¸ì œê°€ ìˆì–´ Podë¥¼ ìŠ¤ì¼€ì¤„ë§í•  ìˆ˜ ì—†ìŒ
# Unknown: ë…¸ë“œì™€ í†µì‹ ì´ ë¶ˆê°€ëŠ¥í•œ ìƒíƒœ
```

### ë…¸ë“œ ì¶”ê°€

```bash
#!/bin/bash
# add-worker-node.sh

NODE_IP=$1
NODE_NAME=$2

if [ -z "$NODE_IP" ] || [ -z "$NODE_NAME" ]; then
    echo "Usage: $0 <node-ip> <node-name>"
    exit 1
fi

echo "Adding new worker node: $NODE_NAME ($NODE_IP)"

# 1. ìƒˆ ë…¸ë“œì—ì„œ ì‚¬ì „ ì¤€ë¹„
ssh root@$NODE_IP "
    # í˜¸ìŠ¤íŠ¸ëª… ì„¤ì •
    hostnamectl set-hostname $NODE_NAME
    
    # í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    yum update -y
    yum install -y containerd.io kubelet kubeadm kubectl
    
    # ì„œë¹„ìŠ¤ í™œì„±í™”
    systemctl enable containerd kubelet
    systemctl start containerd
    
    # ë°©í™”ë²½ ì„¤ì •
    firewall-cmd --permanent --add-port=10250/tcp
    firewall-cmd --permanent --add-port=30000-32767/tcp
    firewall-cmd --reload
    
    # swap ë¹„í™œì„±í™”
    swapoff -a
    sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
"

# 2. join í† í° ìƒì„± (ë§ˆìŠ¤í„°ì—ì„œ)
JOIN_COMMAND=$(kubeadm token create --print-join-command)

# 3. ìƒˆ ë…¸ë“œì—ì„œ í´ëŸ¬ìŠ¤í„° ì¡°ì¸
ssh root@$NODE_IP "$JOIN_COMMAND"

# 4. ë…¸ë“œ ë ˆì´ë¸”ë§
kubectl label node $NODE_NAME node-role.kubernetes.io/worker=worker
kubectl label node $NODE_NAME environment=production

echo "Node $NODE_NAME added successfully!"
```

### ë…¸ë“œ ì œê±°

```bash
#!/bin/bash
# remove-node.sh

NODE_NAME=$1

if [ -z "$NODE_NAME" ]; then
    echo "Usage: $0 <node-name>"
    exit 1
fi

echo "Removing node: $NODE_NAME"

# 1. ë…¸ë“œ ë“œë ˆì¸ (Pod ì´ë™)
echo "Draining node..."
kubectl drain $NODE_NAME --ignore-daemonsets --delete-emptydir-data --force --timeout=300s

# 2. ë…¸ë“œ ì‚­ì œ
echo "Deleting node from cluster..."
kubectl delete node $NODE_NAME

# 3. ë…¸ë“œì—ì„œ kubeadm ë¦¬ì…‹ (ì„ íƒì‚¬í•­)
read -p "Reset kubeadm on the node? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    NODE_IP=$(kubectl get node $NODE_NAME -o jsonpath='{.status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null || echo "")
    if [ -n "$NODE_IP" ]; then
        echo "Resetting kubeadm on $NODE_IP..."
        ssh root@$NODE_IP "
            kubeadm reset -f
            systemctl stop kubelet containerd
            rm -rf /etc/kubernetes/
            rm -rf /var/lib/kubelet/
            rm -rf /var/lib/etcd/
        "
    fi
fi

echo "Node $NODE_NAME removed successfully!"
```

## ğŸ·ï¸ ë…¸ë“œ ë ˆì´ë¸”ë§ê³¼ ì„ íƒ

### í‘œì¤€ ë ˆì´ë¸”ë§ ì „ëµ

```bash
# í•˜ë“œì›¨ì–´ ê¸°ë°˜ ë ˆì´ë¸”
kubectl label node worker-01 hardware.company.com/cpu-type=intel-xeon
kubectl label node worker-01 hardware.company.com/memory-size=32GB
kubectl label node worker-01 hardware.company.com/storage-type=ssd
kubectl label node worker-01 hardware.company.com/network-speed=10gbps

# ìš©ë„ë³„ ë ˆì´ë¸”
kubectl label node worker-01 workload.company.com/type=compute-intensive
kubectl label node worker-02 workload.company.com/type=memory-intensive
kubectl label node worker-03 workload.company.com/type=general-purpose

# í™˜ê²½ë³„ ë ˆì´ë¸”
kubectl label node worker-01 environment=production
kubectl label node worker-02 environment=staging
kubectl label node worker-03 environment=development

# ì§€ì—­/ìœ„ì¹˜ ë ˆì´ë¸”
kubectl label node worker-01 topology.kubernetes.io/zone=zone-a
kubectl label node worker-01 topology.kubernetes.io/region=korea-central

# íŠ¹ìˆ˜ ìš©ë„ ë ˆì´ë¸”
kubectl label node gpu-worker-01 accelerator.company.com/gpu=nvidia-v100
kubectl label node storage-worker-01 storage.company.com/type=ceph-osd
```

### Taintsì™€ Tolerations

```bash
# ìš´ì˜ í™˜ê²½ ì „ìš© ë…¸ë“œ ì„¤ì •
kubectl taint nodes prod-worker-01 environment=production:NoSchedule

# ë°ì´í„°ë² ì´ìŠ¤ ì „ìš© ë…¸ë“œ ì„¤ì •
kubectl taint nodes db-worker-01 workload-type=database:NoSchedule

# GPU ì „ìš© ë…¸ë“œ ì„¤ì •
kubectl taint nodes gpu-worker-01 accelerator=gpu:NoSchedule

# ë§ˆìŠ¤í„° ë…¸ë“œì— ì¼ë°˜ Pod ìŠ¤ì¼€ì¤„ë§ í—ˆìš© (ê°œë°œ í™˜ê²½)
kubectl taint nodes master-01 node-role.kubernetes.io/control-plane:NoSchedule-

# Taint ì œê±°
kubectl taint nodes worker-01 environment=production:NoSchedule-
```

### Pod ë°°ì¹˜ ì „ëµ

```yaml
# pod-placement-examples.yaml
---
# NodeSelectorë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ë°°ì¹˜
apiVersion: v1
kind: Pod
metadata:
  name: web-app
spec:
  nodeSelector:
    workload.company.com/type: general-purpose
    environment: production
  containers:
  - name: web-app
    image: nginx

---
# Affinityë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë°°ì¹˜
apiVersion: apps/v1
kind: Deployment
metadata:
  name: database-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: database-app
  template:
    metadata:
      labels:
        app: database-app
    spec:
      # ì„ í˜¸í•˜ëŠ” ë…¸ë“œ ë°°ì¹˜
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: workload.company.com/type
                operator: In
                values:
                - memory-intensive
          - weight: 50
            preference:
              matchExpressions:
              - key: hardware.company.com/storage-type
                operator: In
                values:
                - ssd
        # Podê°„ ë¶„ì‚° ë°°ì¹˜
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - database-app
              topologyKey: kubernetes.io/hostname
      # Toleration ì„¤ì •
      tolerations:
      - key: workload-type
        operator: Equal
        value: database
        effect: NoSchedule
      containers:
      - name: database
        image: postgres:13
```

## ğŸ“Š ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

### ë¦¬ì†ŒìŠ¤ ì˜ˆì•½ ì„¤ì •

```yaml
# kubelet-config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì˜ˆì•½
systemReserved:
  cpu: "1000m"      # 1 CPU core
  memory: "2Gi"     # 2GB RAM
  ephemeral-storage: "10Gi"

# ì¿ ë²„ë„¤í‹°ìŠ¤ ì»´í¬ë„ŒíŠ¸ ë¦¬ì†ŒìŠ¤ ì˜ˆì•½
kubeReserved:
  cpu: "500m"       # 0.5 CPU core
  memory: "1Gi"     # 1GB RAM
  ephemeral-storage: "5Gi"

# Eviction ì„ê³„ê°’
evictionHard:
  memory.available: "500Mi"
  nodefs.available: "10%"
  nodefs.inodesFree: "5%"
  imagefs.available: "15%"

# Soft Eviction
evictionSoft:
  memory.available: "1Gi"
  nodefs.available: "15%"
evictionSoftGracePeriod:
  memory.available: "1m30s"
  nodefs.available: "2m"

# ì´ë¯¸ì§€ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
imageGCHighThresholdPercent: 85
imageGCLowThresholdPercent: 80

# ì»¨í…Œì´ë„ˆ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
containerGCThreshold:
  minAge: 1m
  maxPerPodContainer: 2
  maxContainers: 240

# ìµœëŒ€ Pod ìˆ˜ ì œí•œ
maxPods: 250
```

### ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

```bash
#!/bin/bash
# node-resource-monitor.sh

echo "=== Node Resource Monitor ==="
echo "Timestamp: $(date)"
echo

# ë…¸ë“œë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
echo "=== Node Resource Usage ==="
kubectl top nodes --sort-by=cpu
echo

# ë…¸ë“œë³„ í• ë‹¹ ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤
echo "=== Node Allocatable Resources ==="
kubectl get nodes -o custom-columns="NAME:.metadata.name,CPU-ALLOC:.status.allocatable.cpu,MEM-ALLOC:.status.allocatable.memory,STORAGE-ALLOC:.status.allocatable.ephemeral-storage"
echo

# ë…¸ë“œë³„ ì‹¤ì œ ì‚¬ìš©ëŸ‰ vs ìš”ì²­ëŸ‰
echo "=== Resource Allocation vs Usage ==="
for node in $(kubectl get nodes -o name | cut -d/ -f2); do
    echo "Node: $node"
    
    # CPU ì •ë³´
    cpu_capacity=$(kubectl get node $node -o jsonpath='{.status.capacity.cpu}')
    cpu_allocatable=$(kubectl get node $node -o jsonpath='{.status.allocatable.cpu}')
    
    # ë©”ëª¨ë¦¬ ì •ë³´  
    mem_capacity=$(kubectl get node $node -o jsonpath='{.status.capacity.memory}')
    mem_allocatable=$(kubectl get node $node -o jsonpath='{.status.allocatable.memory}')
    
    echo "  CPU: $cpu_allocatable/$cpu_capacity"
    echo "  Memory: $mem_allocatable/$mem_capacity"
    
    # í˜„ì¬ ìŠ¤ì¼€ì¤„ëœ Podì˜ ë¦¬ì†ŒìŠ¤ ìš”ì²­ëŸ‰
    kubectl describe node $node | grep -A 5 "Allocated resources:"
    echo
done
```

## ğŸ”§ ë…¸ë“œ ìœ ì§€ë³´ìˆ˜

### ê³„íšëœ ìœ ì§€ë³´ìˆ˜

```bash
#!/bin/bash
# planned-maintenance.sh

NODE_NAME=$1
MAINTENANCE_REASON=${2:-"Planned maintenance"}

if [ -z "$NODE_NAME" ]; then
    echo "Usage: $0 <node-name> [reason]"
    exit 1
fi

echo "Starting planned maintenance for node: $NODE_NAME"
echo "Reason: $MAINTENANCE_REASON"

# 1. ìœ ì§€ë³´ìˆ˜ ì „ ìƒíƒœ ì €ì¥
echo "Saving pre-maintenance state..."
kubectl get pods --all-namespaces --field-selector spec.nodeName=$NODE_NAME -o yaml > "/tmp/pre-maintenance-pods-$NODE_NAME.yaml"

# 2. ë…¸ë“œì— ìœ ì§€ë³´ìˆ˜ ë ˆì´ë¸” ì¶”ê°€
kubectl label node $NODE_NAME maintenance.company.com/status=in-progress
kubectl label node $NODE_NAME maintenance.company.com/reason="$MAINTENANCE_REASON"
kubectl label node $NODE_NAME maintenance.company.com/start-time="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# 3. ë…¸ë“œ ë“œë ˆì¸
echo "Draining node..."
kubectl drain $NODE_NAME \
    --ignore-daemonsets \
    --delete-emptydir-data \
    --timeout=600s \
    --grace-period=60

if [ $? -eq 0 ]; then
    echo "Node successfully drained"
    
    # 4. ì‹¤ì œ ìœ ì§€ë³´ìˆ˜ ì‘ì—… ìˆ˜í–‰
    echo "Node is ready for maintenance"
    echo "Perform your maintenance tasks now..."
    echo "After completion, run: uncordon-node.sh $NODE_NAME"
else
    echo "Failed to drain node. Aborting maintenance."
    kubectl label node $NODE_NAME maintenance.company.com/status=failed
    exit 1
fi
```

### ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ í›„ ë³µêµ¬

```bash
#!/bin/bash
# uncordon-node.sh

NODE_NAME=$1

if [ -z "$NODE_NAME" ]; then
    echo "Usage: $0 <node-name>"
    exit 1
fi

echo "Completing maintenance for node: $NODE_NAME"

# 1. ë…¸ë“œ uncordon
kubectl uncordon $NODE_NAME

# 2. ë…¸ë“œ ìƒíƒœ í™•ì¸
echo "Waiting for node to become Ready..."
timeout=60
while [ $timeout -gt 0 ]; do
    node_status=$(kubectl get node $NODE_NAME --no-headers | awk '{print $2}')
    if [ "$node_status" = "Ready" ]; then
        echo "Node is Ready"
        break
    fi
    sleep 5
    timeout=$((timeout - 5))
done

if [ $timeout -le 0 ]; then
    echo "Warning: Node did not become Ready within 60 seconds"
fi

# 3. ìœ ì§€ë³´ìˆ˜ ë ˆì´ë¸” ì—…ë°ì´íŠ¸
kubectl label node $NODE_NAME maintenance.company.com/status=completed
kubectl label node $NODE_NAME maintenance.company.com/end-time="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# 4. Pod ì¬ë°°ì¹˜ í™•ì¸
echo "Checking Pod redistribution..."
sleep 30
kubectl get pods --all-namespaces --field-selector spec.nodeName=$NODE_NAME

echo "Maintenance completed for node: $NODE_NAME"
```

### ë…¸ë“œ í—¬ìŠ¤ì²´í¬

```bash
#!/bin/bash
# node-health-check.sh

NODE_NAME=$1

check_node_health() {
    local node=$1
    
    echo "=== Health Check for Node: $node ==="
    
    # ë…¸ë“œ ê¸°ë³¸ ìƒíƒœ
    echo "Node Status:"
    kubectl get node $node -o wide
    echo
    
    # ë…¸ë“œ ì¡°ê±´ í™•ì¸
    echo "Node Conditions:"
    kubectl describe node $node | grep -A 20 "Conditions:"
    echo
    
    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    echo "Resource Usage:"
    kubectl top node $node 2>/dev/null || echo "Metrics not available"
    echo
    
    # ë…¸ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì¸ Pod ìƒíƒœ
    echo "Running Pods:"
    kubectl get pods --all-namespaces --field-selector spec.nodeName=$node
    echo
    
    # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ (SSH ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ìš°)
    echo "Disk Usage (via SSH):"
    ssh $node "df -h | grep -E '(Filesystem|/dev/)'" 2>/dev/null || echo "SSH not available"
    echo
    
    # ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ ìƒíƒœ
    echo "System Services (via SSH):"
    ssh $node "systemctl is-active kubelet containerd" 2>/dev/null || echo "SSH not available"
    echo
    
    # kubelet ë¡œê·¸ í™•ì¸
    echo "Recent kubelet logs:"
    kubectl logs -n kube-system $(kubectl get pods -n kube-system -l component=kubelet -o name | head -1) --tail=10 2>/dev/null || echo "kubelet logs not available via kubectl"
}

if [ -z "$NODE_NAME" ]; then
    echo "Performing health check for all nodes..."
    for node in $(kubectl get nodes -o name | cut -d/ -f2); do
        check_node_health $node
        echo "================================"
    done
else
    check_node_health $NODE_NAME
fi
```

## ğŸ” ë…¸ë“œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë…¸ë“œ ë¬¸ì œ

#### 1. NotReady ìƒíƒœ í•´ê²°

```bash
# ë…¸ë“œ ìƒíƒœ ìƒì„¸ í™•ì¸
kubectl describe node <node-name>

# kubelet ìƒíƒœ í™•ì¸
ssh <node-name> "systemctl status kubelet"

# kubelet ë¡œê·¸ í™•ì¸
ssh <node-name> "journalctl -u kubelet -f"

# ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•
ssh <node-name> "
    # 1. kubelet ì¬ì‹œì‘
    systemctl restart kubelet
    
    # 2. containerd ì¬ì‹œì‘
    systemctl restart containerd
    
    # 3. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ ë° ì •ë¦¬
    df -h
    docker system prune -a
    
    # 4. ë©”ëª¨ë¦¬ í™•ì¸
    free -h
"
```

#### 2. Pod ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨

```bash
# ë¦¬ì†ŒìŠ¤ ë¶€ì¡± í™•ì¸
kubectl describe node <node-name> | grep -A 10 "Allocated resources:"

# Taint í™•ì¸
kubectl describe node <node-name> | grep Taints

# ë…¸ë“œ ì–´í”¼ë‹ˆí‹° í™•ì¸
kubectl get pods <pod-name> -o yaml | grep -A 10 affinity
```

#### 3. ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ

```bash
# CNI í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system | grep -E "calico|flannel|weave"

# ë…¸ë“œ ê°„ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± í™•ì¸
ssh <node1> "ping -c 3 <node2-ip>"

# iptables ê·œì¹™ í™•ì¸
ssh <node-name> "iptables -L -n | grep KUBE"
```

## ğŸ“Š ë…¸ë“œ ì„±ëŠ¥ ìµœì í™”

### CPU ìµœì í™”

```bash
# CPU Governor ì„¤ì •
ssh <node-name> "
    # ì„±ëŠ¥ ëª¨ë“œë¡œ ì„¤ì •
    echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
    
    # í˜„ì¬ ì„¤ì • í™•ì¸
    cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor
"

# kubelet CPU ê´€ë¦¬ ì •ì±…
cat > /var/lib/kubelet/config.yaml << 'EOF'
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cpuManagerPolicy: static
topologyManagerPolicy: single-numa-node
reservedSystemCPUs: "0,1"
EOF
```

### ë©”ëª¨ë¦¬ ìµœì í™”

```bash
# ìŠ¤ì™‘ ì™„ì „ ë¹„í™œì„±í™” í™•ì¸
ssh <node-name> "
    swapoff -a
    sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
    cat /proc/swaps
"

# Huge Pages ì„¤ì • (í•„ìš”í•œ ê²½ìš°)
ssh <node-name> "
    echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
    echo 'vm.nr_hugepages = 1024' >> /etc/sysctl.conf
"
```

### ìŠ¤í† ë¦¬ì§€ ìµœì í™”

```bash
# SSD ìµœì í™” ì„¤ì •
ssh <node-name> "
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    echo noop > /sys/block/sda/queue/scheduler
    
    # read-ahead ì„¤ì •
    blockdev --setra 256 /dev/sda
    
    # ì˜êµ¬ ì„¤ì •ì„ ìœ„í•´ /etc/rc.localì— ì¶”ê°€
"
```

## ğŸ“‹ ë…¸ë“œ ê´€ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼ ì ê²€ í•­ëª©
- [ ] ëª¨ë“  ë…¸ë“œê°€ Ready ìƒíƒœì¸ê°€?
- [ ] CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ì„ê³„ì¹˜ ì´í•˜ì¸ê°€?
- [ ] ë””ìŠ¤í¬ ê³µê°„ì´ ì¶©ë¶„í•œê°€?
- [ ] kubelet ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‹¤í–‰ ì¤‘ì¸ê°€?

### ì£¼ê°„ ì ê²€ í•­ëª©  
- [ ] ë…¸ë“œë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íŠ¸ë Œë“œ ë¶„ì„
- [ ] ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ í™•ì¸
- [ ] ë¡œê·¸ íŒŒì¼ í¬ê¸° ì ê²€
- [ ] ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ í™•ì¸

### ì›”ê°„ ì ê²€ í•­ëª©
- [ ] í•˜ë“œì›¨ì–´ ìƒíƒœ ì ê²€
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰
- [ ] ìš©ëŸ‰ ê³„íš ê²€í† 
- [ ] ë°±ì—… ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸

---

> ğŸ’¡ **ì‹¤ì „ ê²½í—˜**: ë…¸ë“œ ê´€ë¦¬ì˜ í•µì‹¬ì€ ì˜ˆë°©ì  ëª¨ë‹ˆí„°ë§ì…ë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ì§€ì†ì ìœ¼ë¡œ ì¶”ì í•˜ê³ , ì„ê³„ê°’ì— ë„ë‹¬í•˜ê¸° ì „ì— ì¡°ì¹˜ë¥¼ ì·¨í•˜ì„¸ìš”. íŠ¹íˆ ì˜¨í”„ë ˜ì—ì„œëŠ” í•˜ë“œì›¨ì–´ ì¥ì• ì— ëŒ€ë¹„í•œ ì—¬ë¶„ ë…¸ë“œ í™•ë³´ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.

íƒœê·¸: #node-management #maintenance #troubleshooting #scaling #onprem