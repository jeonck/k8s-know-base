# 백업과 복원

## 🎯 개요

쿠버네티스 클러스터의 완전한 백업 전략과 재해 복구 절차를 다룹니다. etcd 백업, 애플리케이션 데이터 백업, 설정 백업부터 전체 클러스터 복원까지의 실전 가이드를 제공합니다.

## 🗂️ 백업 전략 개요

### 백업 대상 분류

```
┌─────────────────────────────────────────────────┐
│                Kubernetes Cluster              │
├─────────────────────────────────────────────────┤
│ 1. Control Plane Data                          │
│    - etcd (cluster state)                      │
│    - Certificates (/etc/kubernetes/pki)        │
│    - Configuration files                       │
├─────────────────────────────────────────────────┤
│ 2. Application Data                            │
│    - PersistentVolume data                     │
│    - Database contents                         │
│    - Application files                         │
├─────────────────────────────────────────────────┤
│ 3. Configuration & Secrets                     │
│    - ConfigMaps                                │
│    - Secrets                                   │
│    - RBAC policies                             │
├─────────────────────────────────────────────────┤
│ 4. Application Definitions                     │
│    - YAML manifests                            │
│    - Helm charts                               │
│    - Custom resources                          │
└─────────────────────────────────────────────────┘
```

### 백업 우선순위

| 우선순위 | 백업 대상 | 빈도 | RTO | RPO |
|----------|-----------|------|-----|-----|
| **Critical** | etcd, 인증서 | 매일 | < 1시간 | < 4시간 |
| **High** | 애플리케이션 데이터 | 매일 | < 4시간 | < 8시간 |
| **Medium** | 설정 데이터 | 주간 | < 8시간 | < 24시간 |
| **Low** | 애플리케이션 정의 | 변경 시 | < 24시간 | 변경 시점 |

## 🔧 etcd 백업

### 자동화된 etcd 백업 시스템

```bash
#!/bin/bash
# etcd-backup-system.sh

# 설정 변수
BACKUP_DIR="/var/backups/etcd"
RETENTION_DAYS=30
BACKUP_PREFIX="etcd-snapshot"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${BACKUP_PREFIX}-${DATE}.db"

# etcd 엔드포인트 및 인증서 설정
ETCD_ENDPOINTS="https://127.0.0.1:2379"
ETCD_CACERT="/etc/kubernetes/pki/etcd/ca.crt"
ETCD_CERT="/etc/kubernetes/pki/etcd/server.crt"
ETCD_KEY="/etc/kubernetes/pki/etcd/server.key"

# 로그 설정
LOG_FILE="/var/log/etcd-backup.log"
exec > >(tee -a "$LOG_FILE")
exec 2>&1

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# 백업 디렉토리 생성
create_backup_directory() {
    if [ ! -d "$BACKUP_DIR" ]; then
        mkdir -p "$BACKUP_DIR"
        log "Created backup directory: $BACKUP_DIR"
    fi
}

# etcd 상태 확인
check_etcd_health() {
    log "Checking etcd health..."
    
    ETCDCTL_API=3 etcdctl \
        --endpoints="$ETCD_ENDPOINTS" \
        --cacert="$ETCD_CACERT" \
        --cert="$ETCD_CERT" \
        --key="$ETCD_KEY" \
        endpoint health
    
    if [ $? -ne 0 ]; then
        log "ERROR: etcd health check failed"
        exit 1
    fi
    
    log "etcd health check passed"
}

# etcd 백업 실행
create_etcd_backup() {
    log "Starting etcd backup: $BACKUP_FILE"
    
    # 백업 생성
    ETCDCTL_API=3 etcdctl \
        --endpoints="$ETCD_ENDPOINTS" \
        --cacert="$ETCD_CACERT" \
        --cert="$ETCD_CERT" \
        --key="$ETCD_KEY" \
        snapshot save "$BACKUP_FILE"
    
    if [ $? -eq 0 ]; then
        log "etcd backup created successfully: $BACKUP_FILE"
        
        # 백업 검증
        ETCDCTL_API=3 etcdctl snapshot status "$BACKUP_FILE" --write-out=table
        log "Backup verification completed"
        
        # 압축
        gzip "$BACKUP_FILE"
        log "Backup compressed: ${BACKUP_FILE}.gz"
        
        # 권한 설정
        chmod 600 "${BACKUP_FILE}.gz"
        chown root:root "${BACKUP_FILE}.gz"
        
    else
        log "ERROR: etcd backup failed"
        exit 1
    fi
}

# 인증서 백업
backup_certificates() {
    log "Backing up Kubernetes certificates..."
    
    local cert_backup_file="$BACKUP_DIR/kubernetes-certs-${DATE}.tar.gz"
    
    tar -czf "$cert_backup_file" -C /etc/kubernetes pki/
    
    if [ $? -eq 0 ]; then
        log "Certificates backed up: $cert_backup_file"
        chmod 600 "$cert_backup_file"
    else
        log "ERROR: Certificate backup failed"
    fi
}

# 설정 파일 백업
backup_configs() {
    log "Backing up Kubernetes configuration files..."
    
    local config_backup_file="$BACKUP_DIR/kubernetes-configs-${DATE}.tar.gz"
    
    tar -czf "$config_backup_file" \
        -C /etc/kubernetes \
        admin.conf \
        controller-manager.conf \
        kubelet.conf \
        scheduler.conf \
        manifests/ 2>/dev/null || true
    
    if [ $? -eq 0 ]; then
        log "Configuration files backed up: $config_backup_file"
        chmod 600 "$config_backup_file"
    else
        log "WARNING: Some configuration files may not have been backed up"
    fi
}

# 원격 저장소로 백업 복사
upload_to_remote() {
    local remote_server="backup-server.company.local"
    local remote_path="/backups/kubernetes/etcd"
    
    log "Uploading backups to remote server..."
    
    # 최신 백업 파일들 찾기
    local latest_files=$(find "$BACKUP_DIR" -name "*${DATE}*" -type f)
    
    for file in $latest_files; do
        if command -v rsync >/dev/null 2>&1; then
            rsync -av "$file" "$remote_server:$remote_path/"
            log "Uploaded: $(basename $file)"
        else
            scp "$file" "$remote_server:$remote_path/"
            log "Uploaded: $(basename $file)"
        fi
    done
}

# 오래된 백업 정리
cleanup_old_backups() {
    log "Cleaning up backups older than $RETENTION_DAYS days..."
    
    # 로컬 백업 정리
    find "$BACKUP_DIR" -name "${BACKUP_PREFIX}-*.db.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR" -name "kubernetes-certs-*.tar.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR" -name "kubernetes-configs-*.tar.gz" -mtime +$RETENTION_DAYS -delete
    
    log "Old backup cleanup completed"
}

# 백업 무결성 검증
verify_backup_integrity() {
    log "Verifying backup integrity..."
    
    local latest_backup=$(ls -t "$BACKUP_DIR"/${BACKUP_PREFIX}-*.db.gz | head -1)
    
    if [ -f "$latest_backup" ]; then
        # 압축 해제하여 검증
        local temp_file="/tmp/temp-etcd-verify-$(date +%s).db"
        gunzip -c "$latest_backup" > "$temp_file"
        
        ETCDCTL_API=3 etcdctl snapshot status "$temp_file" --write-out=json | jq '.'
        
        if [ $? -eq 0 ]; then
            log "Backup integrity verification passed"
        else
            log "ERROR: Backup integrity verification failed"
        fi
        
        rm -f "$temp_file"
    else
        log "WARNING: No backup file found for verification"
    fi
}

# 메인 실행
main() {
    log "=== Starting etcd backup process ==="
    
    create_backup_directory
    check_etcd_health
    create_etcd_backup
    backup_certificates
    backup_configs
    verify_backup_integrity
    
    # 원격 백업 (설정된 경우)
    if [ "${ENABLE_REMOTE_BACKUP:-false}" = "true" ]; then
        upload_to_remote
    fi
    
    cleanup_old_backups
    
    log "=== etcd backup process completed successfully ==="
}

# 복원 모드 처리
if [ "$1" = "restore" ]; then
    if [ -z "$2" ]; then
        echo "Usage: $0 restore <backup-file>"
        echo "Available backups:"
        ls -la "$BACKUP_DIR"/${BACKUP_PREFIX}-*.db.gz | tail -10
        exit 1
    fi
    
    restore_etcd_backup "$2"
else
    main "$@"
fi

# etcd 복원 함수
restore_etcd_backup() {
    local backup_file="$1"
    local restore_dir="/var/lib/etcd-restore"
    
    log "=== Starting etcd restore process ==="
    log "Backup file: $backup_file"
    
    # 백업 파일 존재 확인
    if [ ! -f "$backup_file" ]; then
        log "ERROR: Backup file not found: $backup_file"
        exit 1
    fi
    
    # 압축된 백업인 경우 압축 해제
    local restore_file="$backup_file"
    if [[ "$backup_file" == *.gz ]]; then
        restore_file="/tmp/etcd-restore-$(date +%s).db"
        gunzip -c "$backup_file" > "$restore_file"
        log "Decompressed backup file"
    fi
    
    # 기존 etcd 데이터 백업
    if [ -d "/var/lib/etcd" ]; then
        mv /var/lib/etcd "/var/lib/etcd-backup-$(date +%s)"
        log "Moved existing etcd data to backup location"
    fi
    
    # etcd 복원
    ETCDCTL_API=3 etcdctl snapshot restore "$restore_file" \
        --data-dir="$restore_dir" \
        --name="default" \
        --initial-cluster="default=https://127.0.0.1:2380" \
        --initial-advertise-peer-urls="https://127.0.0.1:2380"
    
    if [ $? -eq 0 ]; then
        # 복원된 데이터를 올바른 위치로 이동
        mv "$restore_dir" "/var/lib/etcd"
        chown -R etcd:etcd /var/lib/etcd
        
        log "etcd restore completed successfully"
        log "Please restart the kubelet and etcd services"
        log "systemctl restart kubelet"
        
        # 임시 파일 정리
        if [[ "$backup_file" == *.gz ]]; then
            rm -f "$restore_file"
        fi
    else
        log "ERROR: etcd restore failed"
        exit 1
    fi
}
```

### etcd 백업 자동화 (Kubernetes CronJob)

```yaml
# etcd-backup-cronjob.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: etcd-backup-script
  namespace: kube-system
data:
  backup.sh: |
    #!/bin/bash
    
    BACKUP_DIR="/backup"
    DATE=$(date +%Y%m%d_%H%M%S)
    BACKUP_FILE="$BACKUP_DIR/etcd-snapshot-$DATE.db"
    
    # etcd 백업 생성
    ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        snapshot save "$BACKUP_FILE"
    
    # 백업 검증
    ETCDCTL_API=3 etcdctl snapshot status "$BACKUP_FILE"
    
    # 압축
    gzip "$BACKUP_FILE"
    
    echo "Backup completed: ${BACKUP_FILE}.gz"

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etcd-backup
  namespace: kube-system
spec:
  schedule: "0 2 * * *"  # 매일 오전 2시
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          tolerations:
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
            effect: NoSchedule
          nodeSelector:
            node-role.kubernetes.io/control-plane: ""
          hostNetwork: true
          containers:
          - name: etcd-backup
            image: k8s.gcr.io/etcd:3.5.6-0
            command: ["/bin/sh"]
            args: ["/scripts/backup.sh"]
            volumeMounts:
            - name: etcd-certs
              mountPath: /etc/kubernetes/pki/etcd
              readOnly: true
            - name: backup-volume
              mountPath: /backup
            - name: script
              mountPath: /scripts
            resources:
              requests:
                cpu: 100m
                memory: 128Mi
              limits:
                cpu: 500m
                memory: 512Mi
          volumes:
          - name: etcd-certs
            hostPath:
              path: /etc/kubernetes/pki/etcd
              type: Directory
          - name: backup-volume
            persistentVolumeClaim:
              claimName: etcd-backup-pvc
          - name: script
            configMap:
              name: etcd-backup-script
              defaultMode: 0755
          restartPolicy: OnFailure

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: etcd-backup-pvc
  namespace: kube-system
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: backup-storage
  resources:
    requests:
      storage: 50Gi
```

## 💾 애플리케이션 데이터 백업

### Velero를 이용한 클러스터 백업

```bash
#!/bin/bash
# install-velero.sh

# Velero 설치 및 설정
install_velero() {
    echo "Installing Velero..."
    
    # Velero CLI 다운로드
    VELERO_VERSION="v1.11.1"
    wget "https://github.com/vmware-tanzu/velero/releases/download/$VELERO_VERSION/velero-$VELERO_VERSION-linux-amd64.tar.gz"
    tar -xzf "velero-$VELERO_VERSION-linux-amd64.tar.gz"
    sudo mv "velero-$VELERO_VERSION-linux-amd64/velero" /usr/local/bin/
    
    # MinIO를 백업 스토리지로 설정
    kubectl create namespace velero
    
    # MinIO 자격증명 생성
    cat > credentials-velero << EOF
[default]
aws_access_key_id = minio
aws_secret_access_key = minio123
EOF
    
    kubectl create secret generic cloud-credentials \
        --namespace velero \
        --from-file cloud=credentials-velero
    
    # Velero 설치 (MinIO 백엔드)
    velero install \
        --provider aws \
        --plugins velero/velero-plugin-for-aws:v1.7.1 \
        --bucket velero-backups \
        --secret-file ./credentials-velero \
        --use-volume-snapshots=false \
        --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://minio.minio.svc.cluster.local:9000 \
        --use-node-agent
    
    echo "Velero installation completed"
}

# MinIO 스토리지 서버 배포
deploy_minio() {
    echo "Deploying MinIO for backup storage..."
    
    cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: minio

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: minio
spec:
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        command:
        - /bin/bash
        - -c
        args: 
        - minio server /data --console-address :9001
        env:
        - name: MINIO_ROOT_USER
          value: "minio"
        - name: MINIO_ROOT_PASSWORD
          value: "minio123"
        ports:
        - containerPort: 9000
          name: api
        - containerPort: 9001
          name: console
        volumeMounts:
        - name: storage
          mountPath: /data
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: minio-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: minio-pvc
  namespace: minio
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: backup-storage
  resources:
    requests:
      storage: 100Gi

---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: minio
spec:
  selector:
    app: minio
  ports:
  - port: 9000
    targetPort: 9000
    name: api
  - port: 9001
    targetPort: 9001
    name: console
EOF
    
    echo "MinIO deployment completed"
}

install_velero
deploy_minio
```

### 백업 스케줄 설정

```yaml
# velero-backup-schedules.yaml
---
# 전체 클러스터 일일 백업
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: daily-cluster-backup
  namespace: velero
spec:
  schedule: "0 1 * * *"  # 매일 오전 1시
  template:
    includedNamespaces:
    - "*"
    excludedNamespaces:
    - kube-system
    - kube-public
    - kube-node-lease
    - velero
    storageLocation: default
    ttl: 720h0m0s  # 30일 보관
    includeClusterResources: true
    snapshotVolumes: true

---
# 운영 환경 백업 (높은 빈도)
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: production-backup
  namespace: velero
spec:
  schedule: "0 */6 * * *"  # 6시간마다
  template:
    includedNamespaces:
    - production
    storageLocation: default
    ttl: 168h0m0s  # 7일 보관
    includeClusterResources: false
    snapshotVolumes: true
    labelSelector:
      matchLabels:
        backup.company.com/include: "true"

---
# 데이터베이스 백업 (매시간)
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: database-backup
  namespace: velero
spec:
  schedule: "0 * * * *"  # 매시간
  template:
    includedNamespaces:
    - production
    storageLocation: default
    ttl: 72h0m0s  # 3일 보관
    includeClusterResources: false
    snapshotVolumes: true
    labelSelector:
      matchLabels:
        app.kubernetes.io/component: database

---
# 주간 전체 백업 (장기 보관)
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: weekly-full-backup
  namespace: velero
spec:
  schedule: "0 3 * * 0"  # 매주 일요일 오전 3시
  template:
    includedNamespaces:
    - "*"
    storageLocation: default
    ttl: 8760h0m0s  # 1년 보관
    includeClusterResources: true
    snapshotVolumes: true
```

### 애플리케이션별 백업 전략

```yaml
# application-backup-annotations.yaml
---
# 데이터베이스 Pod - Pre/Post 훅 설정
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  namespace: production
  annotations:
    backup.company.com/include: "true"
    backup.company.com/strategy: "database"
spec:
  template:
    metadata:
      annotations:
        # Velero 백업 훅
        pre.hook.backup.velero.io/command: '["/bin/bash", "-c", "mysqldump --single-transaction --routines --triggers -u root -p$MYSQL_ROOT_PASSWORD --all-databases > /backup/mysql-dump.sql"]'
        pre.hook.backup.velero.io/timeout: "3m"
        post.hook.backup.velero.io/command: '["/bin/bash", "-c", "rm -f /backup/mysql-dump.sql"]'
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
        - name: backup-temp
          mountPath: /backup
      volumes:
      - name: mysql-data
        persistentVolumeClaim:
          claimName: mysql-pvc
      - name: backup-temp
        emptyDir: {}

---
# 웹 애플리케이션 - 상태 없는 서비스
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: production
  annotations:
    backup.company.com/include: "true"
    backup.company.com/strategy: "stateless"
    backup.velero.io/backup-volumes-excludes: "tmp,cache"
spec:
  template:
    spec:
      containers:
      - name: web-app
        image: nginx:1.21
        volumeMounts:
        - name: web-content
          mountPath: /usr/share/nginx/html
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /var/cache/nginx
      volumes:
      - name: web-content
        persistentVolumeClaim:
          claimName: web-content-pvc
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
```

## 🔄 데이터베이스 백업 자동화

### MySQL/PostgreSQL 백업 시스템

```bash
#!/bin/bash
# database-backup-system.sh

# 설정
DB_TYPE="mysql"  # mysql 또는 postgresql
NAMESPACE="production"
BACKUP_STORAGE_CLASS="backup-storage"
RETENTION_DAYS=30

# MySQL 백업 함수
backup_mysql() {
    local db_pod=$1
    local backup_name="mysql-backup-$(date +%Y%m%d-%H%M%S)"
    
    echo "Creating MySQL backup: $backup_name"
    
    # 백업 Job 생성
    cat << EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: $backup_name
  namespace: $NAMESPACE
spec:
  template:
    spec:
      containers:
      - name: mysql-backup
        image: mysql:8.0
        command: ["/bin/bash"]
        args:
        - -c
        - |
          # 데이터베이스 백업 생성
          mysqldump --single-transaction --routines --triggers \
            -h \$MYSQL_HOST -u \$MYSQL_USER -p\$MYSQL_PASSWORD \
            --all-databases > /backup/mysql-dump-\$(date +%Y%m%d-%H%M%S).sql
          
          # 압축
          gzip /backup/mysql-dump-*.sql
          
          echo "MySQL backup completed"
        env:
        - name: MYSQL_HOST
          value: "mysql-service"
        - name: MYSQL_USER
          value: "root"
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: backup-volume
          mountPath: /backup
      volumes:
      - name: backup-volume
        persistentVolumeClaim:
          claimName: mysql-backup-pvc
      restartPolicy: OnFailure
  backoffLimit: 3

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-backup-pvc
  namespace: $NAMESPACE
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: $BACKUP_STORAGE_CLASS
  resources:
    requests:
      storage: 50Gi
EOF
}

# PostgreSQL 백업 함수
backup_postgresql() {
    local db_pod=$1
    local backup_name="postgresql-backup-$(date +%Y%m%d-%H%M%S)"
    
    echo "Creating PostgreSQL backup: $backup_name"
    
    cat << EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: $backup_name
  namespace: $NAMESPACE
spec:
  template:
    spec:
      containers:
      - name: postgresql-backup
        image: postgres:13
        command: ["/bin/bash"]
        args:
        - -c
        - |
          # 모든 데이터베이스 백업
          pg_dumpall -h \$POSTGRES_HOST -U \$POSTGRES_USER \
            > /backup/postgresql-dump-\$(date +%Y%m%d-%H%M%S).sql
          
          # 압축
          gzip /backup/postgresql-dump-*.sql
          
          echo "PostgreSQL backup completed"
        env:
        - name: POSTGRES_HOST
          value: "postgresql-service"
        - name: POSTGRES_USER
          value: "postgres"
        - name: PGPASSWORD
          valueFrom:
            secretKeyRef:
              name: postgresql-secret
              key: password
        volumeMounts:
        - name: backup-volume
          mountPath: /backup
      volumes:
      - name: backup-volume
        persistentVolumeClaim:
          claimName: postgresql-backup-pvc
      restartPolicy: OnFailure
  backoffLimit: 3
EOF
}

# 백업 정리 함수
cleanup_old_backups() {
    echo "Cleaning up backups older than $RETENTION_DAYS days..."
    
    # 오래된 백업 Job 삭제
    kubectl get jobs -n $NAMESPACE -o json | jq -r \
        ".items[] | select(.metadata.name | test(\"^(mysql|postgresql)-backup-\")) | select(.metadata.creationTimestamp | fromdateiso8601 < (now - ($RETENTION_DAYS * 86400))) | .metadata.name" | \
        xargs -r kubectl delete job -n $NAMESPACE
}

# 메인 실행
case $DB_TYPE in
    mysql)
        backup_mysql "mysql-0"
        ;;
    postgresql)
        backup_postgresql "postgresql-0"
        ;;
    *)
        echo "Unsupported database type: $DB_TYPE"
        exit 1
        ;;
esac

cleanup_old_backups
```

### 데이터베이스 백업 CronJob

```yaml
# database-backup-cronjobs.yaml
---
# MySQL 자동 백업
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mysql-backup-cron
  namespace: production
spec:
  schedule: "0 2 * * *"  # 매일 오전 2시
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mysql-backup
            image: mysql:8.0
            command: ["/bin/bash"]
            args:
            - -c
            - |
              BACKUP_FILE="/backup/mysql-backup-$(date +%Y%m%d-%H%M%S).sql"
              
              echo "Starting MySQL backup: $BACKUP_FILE"
              
              # 백업 실행
              mysqldump --single-transaction --routines --triggers \
                -h $MYSQL_HOST -u $MYSQL_USER -p$MYSQL_PASSWORD \
                --all-databases > "$BACKUP_FILE"
              
              if [ $? -eq 0 ]; then
                # 압축
                gzip "$BACKUP_FILE"
                echo "MySQL backup completed successfully: ${BACKUP_FILE}.gz"
                
                # 백업 파일 크기 확인
                ls -lh "${BACKUP_FILE}.gz"
                
                # 오래된 백업 정리 (30일 이상)
                find /backup -name "mysql-backup-*.sql.gz" -mtime +30 -delete
                echo "Old backup cleanup completed"
              else
                echo "MySQL backup failed"
                exit 1
              fi
            env:
            - name: MYSQL_HOST
              value: "mysql-service"
            - name: MYSQL_USER
              value: "backup"
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-backup-secret
                  key: password
            volumeMounts:
            - name: backup-volume
              mountPath: /backup
            resources:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                cpu: 500m
                memory: 1Gi
          volumes:
          - name: backup-volume
            persistentVolumeClaim:
              claimName: mysql-backup-pvc
          restartPolicy: OnFailure

---
# PostgreSQL 자동 백업
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgresql-backup-cron
  namespace: production
spec:
  schedule: "30 2 * * *"  # 매일 오전 2시 30분
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: postgresql-backup
            image: postgres:13
            command: ["/bin/bash"]
            args:
            - -c
            - |
              BACKUP_FILE="/backup/postgresql-backup-$(date +%Y%m%d-%H%M%S).sql"
              
              echo "Starting PostgreSQL backup: $BACKUP_FILE"
              
              # 전체 클러스터 백업
              pg_dumpall -h $POSTGRES_HOST -U $POSTGRES_USER > "$BACKUP_FILE"
              
              if [ $? -eq 0 ]; then
                # 압축
                gzip "$BACKUP_FILE"
                echo "PostgreSQL backup completed: ${BACKUP_FILE}.gz"
                
                # 백업 검증
                zcat "${BACKUP_FILE}.gz" | head -10
                
                # 오래된 백업 정리
                find /backup -name "postgresql-backup-*.sql.gz" -mtime +30 -delete
              else
                echo "PostgreSQL backup failed"
                exit 1
              fi
            env:
            - name: POSTGRES_HOST
              value: "postgresql-service"
            - name: POSTGRES_USER
              value: "postgres"
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-secret
                  key: password
            volumeMounts:
            - name: backup-volume
              mountPath: /backup
          volumes:
          - name: backup-volume
            persistentVolumeClaim:
              claimName: postgresql-backup-pvc
          restartPolicy: OnFailure
```

## ⚡ 재해 복구 절차

### 전체 클러스터 복원

```bash
#!/bin/bash
# cluster-disaster-recovery.sh

BACKUP_DATE=${1:-$(date +%Y%m%d)}
ETCD_BACKUP_DIR="/var/backups/etcd"
VELERO_BACKUP_NAME=""

echo "=== Kubernetes Cluster Disaster Recovery ==="
echo "Backup date: $BACKUP_DATE"

# 1. etcd 복원
restore_etcd() {
    echo "Step 1: Restoring etcd..."
    
    local etcd_backup=$(find "$ETCD_BACKUP_DIR" -name "*${BACKUP_DATE}*.db.gz" | head -1)
    
    if [ -z "$etcd_backup" ]; then
        echo "ERROR: No etcd backup found for date $BACKUP_DATE"
        exit 1
    fi
    
    echo "Using etcd backup: $etcd_backup"
    
    # 모든 마스터 노드에서 etcd 중지
    for master in $(kubectl get nodes -l node-role.kubernetes.io/control-plane -o name | cut -d/ -f2); do
        echo "Stopping etcd on $master"
        ssh "$master" "systemctl stop kubelet"
        ssh "$master" "systemctl stop etcd" 2>/dev/null || true
    done
    
    # 기존 etcd 데이터 백업
    ssh "$MASTER_NODE" "mv /var/lib/etcd /var/lib/etcd-backup-$(date +%s)" 2>/dev/null || true
    
    # etcd 복원 실행
    local temp_file="/tmp/etcd-restore.db"
    gunzip -c "$etcd_backup" > "$temp_file"
    
    ETCDCTL_API=3 etcdctl snapshot restore "$temp_file" \
        --data-dir="/var/lib/etcd" \
        --name="default" \
        --initial-cluster="default=https://127.0.0.1:2380" \
        --initial-advertise-peer-urls="https://127.0.0.1:2380"
    
    # 권한 설정
    chown -R etcd:etcd /var/lib/etcd
    
    # kubelet 시작
    systemctl start kubelet
    
    echo "etcd restoration completed"
}

# 2. 클러스터 상태 확인
verify_cluster_health() {
    echo "Step 2: Verifying cluster health..."
    
    # API 서버 응답 대기
    local timeout=300
    while [ $timeout -gt 0 ]; do
        if kubectl cluster-info >/dev/null 2>&1; then
            echo "✅ API server is responding"
            break
        fi
        echo "Waiting for API server... ($timeout seconds remaining)"
        sleep 10
        timeout=$((timeout - 10))
    done
    
    if [ $timeout -le 0 ]; then
        echo "❌ API server is not responding after 5 minutes"
        exit 1
    fi
    
    # 노드 상태 확인
    echo "Node status:"
    kubectl get nodes
    
    # 시스템 Pod 상태 확인
    echo "System pods status:"
    kubectl get pods -n kube-system
}

# 3. 애플리케이션 데이터 복원 (Velero)
restore_applications() {
    echo "Step 3: Restoring applications with Velero..."
    
    # 사용 가능한 백업 확인
    velero backup get | grep "$BACKUP_DATE"
    
    if [ $? -ne 0 ]; then
        echo "WARNING: No Velero backup found for $BACKUP_DATE"
        echo "Available backups:"
        velero backup get
        return 1
    fi
    
    # 운영 네임스페이스 복원
    VELERO_BACKUP_NAME=$(velero backup get | grep "$BACKUP_DATE" | grep "production" | head -1 | awk '{print $1}')
    
    if [ -n "$VELERO_BACKUP_NAME" ]; then
        echo "Restoring from Velero backup: $VELERO_BACKUP_NAME"
        
        velero restore create \
            --from-backup "$VELERO_BACKUP_NAME" \
            --restore-volumes=true \
            --wait
        
        echo "Velero restoration completed"
    fi
}

# 4. 데이터베이스 복원
restore_databases() {
    echo "Step 4: Restoring databases..."
    
    # MySQL 복원
    if kubectl get deployment mysql -n production >/dev/null 2>&1; then
        echo "Restoring MySQL database..."
        
        local mysql_backup="/backup/mysql-backup-${BACKUP_DATE}*.sql.gz"
        local backup_file=$(ls $mysql_backup 2>/dev/null | head -1)
        
        if [ -f "$backup_file" ]; then
            # MySQL Pod에서 복원 실행
            kubectl exec -n production deployment/mysql -- bash -c "
                gunzip -c /backup/$(basename $backup_file) | mysql -u root -p\$MYSQL_ROOT_PASSWORD
            "
            echo "MySQL restoration completed"
        else
            echo "WARNING: MySQL backup not found for $BACKUP_DATE"
        fi
    fi
    
    # PostgreSQL 복원
    if kubectl get deployment postgresql -n production >/dev/null 2>&1; then
        echo "Restoring PostgreSQL database..."
        
        local pg_backup="/backup/postgresql-backup-${BACKUP_DATE}*.sql.gz"
        local backup_file=$(ls $pg_backup 2>/dev/null | head -1)
        
        if [ -f "$backup_file" ]; then
            kubectl exec -n production deployment/postgresql -- bash -c "
                gunzip -c /backup/$(basename $backup_file) | psql -U postgres
            "
            echo "PostgreSQL restoration completed"
        else
            echo "WARNING: PostgreSQL backup not found for $BACKUP_DATE"
        fi
    fi
}

# 5. 서비스 검증
verify_services() {
    echo "Step 5: Verifying services..."
    
    # 모든 Pod가 Running 상태가 될 때까지 대기
    echo "Waiting for all pods to be ready..."
    kubectl wait --for=condition=Ready pods --all --all-namespaces --timeout=600s
    
    # 서비스 엔드포인트 확인
    echo "Service endpoints:"
    kubectl get endpoints --all-namespaces | grep -v "none"
    
    # Ingress 상태 확인
    echo "Ingress status:"
    kubectl get ingress --all-namespaces
    
    # 기본 연결성 테스트
    echo "Testing basic connectivity..."
    kubectl run connectivity-test --image=busybox --rm -it --restart=Never -- \
        nslookup kubernetes.default.svc.cluster.local
}

# 6. 복원 후 검증 체크리스트
post_recovery_checklist() {
    echo "Step 6: Post-recovery checklist..."
    
    cat << EOF
=== Post-Recovery Checklist ===

□ Cluster Status
  - API server responding: $(kubectl cluster-info >/dev/null 2>&1 && echo "✅" || echo "❌")
  - All nodes ready: $(kubectl get nodes | grep -c "Ready")
  - System pods running: $(kubectl get pods -n kube-system | grep -c "Running")

□ Application Status
  - Production pods: $(kubectl get pods -n production | grep -c "Running")
  - Database connections: [Manual verification needed]
  - External services: [Manual verification needed]

□ Data Integrity
  - Database consistency: [Manual verification needed]
  - File system integrity: [Manual verification needed]
  - Backup verification: [Manual verification needed]

□ Security
  - Certificate validity: $(kubeadm certs check-expiration | grep -c "CERTIFICATE")
  - RBAC policies: [Manual verification needed]
  - Network policies: [Manual verification needed]

□ Monitoring
  - Prometheus targets: [Manual verification needed]
  - Grafana dashboards: [Manual verification needed]
  - Alerting rules: [Manual verification needed]

Next steps:
1. Verify application functionality
2. Check data consistency
3. Monitor system performance
4. Update backup schedules if needed
5. Document lessons learned
EOF
}

# 메인 실행
main() {
    echo "Starting disaster recovery process..."
    read -p "This will restore the cluster from backups. Continue? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Recovery aborted"
        exit 0
    fi
    
    restore_etcd
    verify_cluster_health
    restore_applications
    restore_databases
    verify_services
    post_recovery_checklist
    
    echo ""
    echo "=== Disaster Recovery Completed ==="
    echo "Please review the checklist above and perform manual verifications."
}

# 실행
if [ "$1" = "--dry-run" ]; then
    echo "DRY RUN MODE - No actual changes will be made"
    echo "Would restore from backups dated: $BACKUP_DATE"
    exit 0
else
    main "$@"
fi
```

## 📋 백업 검증 및 모니터링

### 백업 상태 모니터링

```bash
#!/bin/bash
# backup-monitoring.sh

echo "=== Backup Status Monitoring ==="

# etcd 백업 상태 확인
check_etcd_backups() {
    echo "1. etcd Backup Status:"
    
    local backup_dir="/var/backups/etcd"
    local latest_backup=$(ls -t "$backup_dir"/etcd-snapshot-*.db.gz 2>/dev/null | head -1)
    
    if [ -n "$latest_backup" ]; then
        local backup_age=$(find "$latest_backup" -mtime +1 2>/dev/null)
        if [ -z "$backup_age" ]; then
            echo "  ✅ Latest etcd backup: $(basename $latest_backup)"
            echo "     Age: $(stat -c %y "$latest_backup")"
            echo "     Size: $(du -h "$latest_backup" | awk '{print $1}')"
        else
            echo "  ⚠️ etcd backup is older than 24 hours"
            echo "     Latest backup: $(basename $latest_backup)"
        fi
    else
        echo "  ❌ No etcd backups found"
    fi
    echo
}

# Velero 백업 상태 확인
check_velero_backups() {
    echo "2. Velero Backup Status:"
    
    if command -v velero >/dev/null 2>&1; then
        echo "Recent Velero backups:"
        velero backup get | head -10
        
        # 실패한 백업 확인
        local failed_backups=$(velero backup get | grep -c "Failed\|PartiallyFailed")
        if [ "$failed_backups" -gt 0 ]; then
            echo "  ⚠️ $failed_backups failed backup(s) found"
            velero backup get | grep -E "Failed|PartiallyFailed"
        else
            echo "  ✅ No failed backups"
        fi
    else
        echo "  ⚠️ Velero CLI not available"
    fi
    echo
}

# 데이터베이스 백업 상태 확인
check_database_backups() {
    echo "3. Database Backup Status:"
    
    # MySQL 백업 확인
    if kubectl get pvc mysql-backup-pvc -n production >/dev/null 2>&1; then
        local mysql_pod=$(kubectl get pods -n production -l app=mysql-backup -o name | head -1)
        if [ -n "$mysql_pod" ]; then
            local latest_mysql=$(kubectl exec -n production "$mysql_pod" -- ls -t /backup/mysql-backup-*.sql.gz 2>/dev/null | head -1)
            if [ -n "$latest_mysql" ]; then
                echo "  ✅ Latest MySQL backup: $latest_mysql"
            else
                echo "  ❌ No MySQL backups found"
            fi
        fi
    fi
    
    # PostgreSQL 백업 확인
    if kubectl get pvc postgresql-backup-pvc -n production >/dev/null 2>&1; then
        local pg_pod=$(kubectl get pods -n production -l app=postgresql-backup -o name | head -1)
        if [ -n "$pg_pod" ]; then
            local latest_pg=$(kubectl exec -n production "$pg_pod" -- ls -t /backup/postgresql-backup-*.sql.gz 2>/dev/null | head -1)
            if [ -n "$latest_pg" ]; then
                echo "  ✅ Latest PostgreSQL backup: $latest_pg"
            else
                echo "  ❌ No PostgreSQL backups found"
            fi
        fi
    fi
    echo
}

# 백업 일정 확인
check_backup_schedules() {
    echo "4. Backup Schedule Status:"
    
    # CronJob 상태 확인
    echo "Active backup CronJobs:"
    kubectl get cronjobs --all-namespaces | grep -E "(backup|etcd)" | while read ns name schedule suspend active last; do
        if [ "$suspend" = "False" ]; then
            echo "  ✅ $ns/$name - Next: $schedule"
        else
            echo "  ⚠️ $ns/$name - SUSPENDED"
        fi
    done
    
    # Velero 스케줄 확인
    if command -v velero >/dev/null 2>&1; then
        echo
        echo "Velero backup schedules:"
        velero schedule get
    fi
    echo
}

# 스토리지 용량 확인
check_backup_storage() {
    echo "5. Backup Storage Usage:"
    
    # 백업 PVC 용량 확인
    kubectl get pvc --all-namespaces | grep backup | while read ns name status volume capacity access storage class age; do
        echo "  $ns/$name: $capacity ($status)"
    done
    echo
}

# 실행
check_etcd_backups
check_velero_backups
check_database_backups
check_backup_schedules
check_backup_storage

echo "=== Backup Monitoring Completed ==="
```

## 📝 백업 베스트 프랙티스

### 1. 백업 전략 수립

- **3-2-1 규칙**: 3개 복사본, 2개 다른 미디어, 1개 오프사이트
- **RTO/RPO 정의**: 비즈니스 요구사항에 따른 목표 설정
- **정기 테스트**: 백업 복원 절차의 정기적 테스트
- **문서화**: 모든 백업 및 복원 절차 문서화

### 2. 자동화 및 모니터링

- **자동화된 백업**: CronJob을 통한 정기 백업
- **백업 검증**: 백업 파일의 무결성 정기 검증
- **알림 설정**: 백업 실패 시 즉시 알림
- **용량 관리**: 백업 스토리지 용량 모니터링

### 3. 보안 고려사항

- **암호화**: 전송 중 및 저장 시 암호화
- **접근 제어**: 백업 데이터에 대한 엄격한 접근 제어
- **감사 로그**: 백업 관련 모든 활동 로깅
- **오프사이트 저장**: 재해 대비 오프사이트 백업

---

> 💡 **실전 경험**: 백업의 핵심은 복원 테스트입니다. 정기적으로 백업에서 복원 테스트를 수행하여 실제 재해 상황에서 신속하게 대응할 수 있도록 준비하세요. 특히 etcd 백업은 클러스터의 생명선이므로 매일 백업하고 주기적으로 복원 테스트를 수행하는 것이 중요합니다.

태그: #backup #disaster-recovery #etcd #velero #database #restoration #onprem
