# 성능 튜닝

## 🎯 개요

쿠버네티스 클러스터의 전반적인 성능 최적화 방법을 다룹니다. 컨트롤 플레인, 워커 노드, 네트워크, 스토리지, 그리고 애플리케이션 레벨에서의 튜닝 전략과 실전 기법을 포함합니다.

## 🏗️ 컨트롤 플레인 성능 튜닝

### etcd 최적화

```bash
#!/bin/bash
# etcd-optimization.sh

# etcd 성능 설정 최적화
optimize_etcd_configuration() {
    echo "Optimizing etcd configuration..."
    
    # etcd 설정 파일 수정
    cat > /etc/kubernetes/manifests/etcd-optimization.yaml << 'EOF'
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.1.10:2379
  labels:
    component: etcd
    tier: control-plane
  name: etcd
  namespace: kube-system
spec:
  containers:
  - command:
    - etcd
    - --advertise-client-urls=https://192.168.1.10:2379
    - --cert-file=/etc/kubernetes/pki/etcd/server.crt
    - --client-cert-auth=true
    - --data-dir=/var/lib/etcd
    - --initial-advertise-peer-urls=https://192.168.1.10:2380
    - --initial-cluster=master=https://192.168.1.10:2380
    - --key-file=/etc/kubernetes/pki/etcd/server.key
    - --listen-client-urls=https://127.0.0.1:2379,https://192.168.1.10:2379
    - --listen-metrics-urls=http://127.0.0.1:2381
    - --listen-peer-urls=https://192.168.1.10:2380
    - --name=master
    - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
    - --peer-client-cert-auth=true
    - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
    - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
    - --snapshot-count=10000
    - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
    # 성능 최적화 파라미터
    - --heartbeat-interval=100
    - --election-timeout=1000
    - --max-snapshots=5
    - --max-wals=5
    - --quota-backend-bytes=8589934592  # 8GB
    - --auto-compaction-retention=1h
    - --auto-compaction-mode=periodic
EOF

    echo "etcd configuration optimized"
}

# etcd 압축 및 조각 모음
defragment_etcd() {
    echo "Defragmenting etcd..."
    
    # etcd 엔드포인트 확인
    ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        endpoint status --write-out=table
    
    # 압축 실행
    ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        compact $(ETCDCTL_API=3 etcdctl \
            --endpoints=https://127.0.0.1:2379 \
            --cacert=/etc/kubernetes/pki/etcd/ca.crt \
            --cert=/etc/kubernetes/pki/etcd/server.crt \
            --key=/etc/kubernetes/pki/etcd/server.key \
            endpoint status --write-out="json" | jq '.[0].Status.header.revision')
    
    # 조각 모음 실행
    ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        defrag
    
    echo "etcd defragmentation completed"
}

# etcd 모니터링 메트릭 수집
monitor_etcd_performance() {
    echo "=== etcd Performance Metrics ==="
    
    # etcd 상태 확인
    ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        endpoint status --write-out=table
    
    # etcd 메트릭 확인
    curl -s http://127.0.0.1:2381/metrics | grep -E "(etcd_server_proposals|etcd_disk_wal_fsync|etcd_disk_backend_commit)"
}

optimize_etcd_configuration
defragment_etcd
monitor_etcd_performance
```

### API Server 최적화

```yaml
# apiserver-optimization.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=192.168.1.10
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --requestheader-allowed-names=front-proxy-client
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    # 성능 최적화 파라미터
    - --max-requests-inflight=400
    - --max-mutating-requests-inflight=200
    - --default-watch-cache-size=1000
    - --watch-cache-sizes=nodes#1000,pods#5000
    - --enable-aggregator-routing=true
    - --request-timeout=60s
    - --min-request-timeout=1800
    # 이벤트 TTL 설정
    - --event-ttl=24h
    # 감사 로그 최적화
    - --audit-log-maxage=7
    - --audit-log-maxbackup=3
    - --audit-log-maxsize=100
    # 압축 활성화
    - --enable-gzip=true
    image: k8s.gcr.io/kube-apiserver:v1.28.0
    imagePullPolicy: IfNotPresent
    name: kube-apiserver
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 2000m
        memory: 2Gi
```

## 🖥️ 노드 레벨 최적화

### 시스템 커널 파라미터 튜닝

```bash
#!/bin/bash
# system-optimization.sh

# 커널 파라미터 최적화
optimize_kernel_parameters() {
    echo "Optimizing kernel parameters..."
    
    cat > /etc/sysctl.d/99-kubernetes-performance.conf << 'EOF'
# 네트워크 성능 최적화
net.core.netdev_max_backlog = 5000
net.core.rmem_default = 262144
net.core.rmem_max = 16777216
net.core.wmem_default = 262144
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 65536 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_congestion_control = bbr
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_tw_reuse = 1

# 파일 시스템 최적화
fs.file-max = 2097152
fs.inotify.max_user_instances = 512
fs.inotify.max_user_watches = 524288
fs.nr_open = 1048576

# 메모리 관리 최적화
vm.swappiness = 1
vm.dirty_background_ratio = 5
vm.dirty_ratio = 10
vm.vfs_cache_pressure = 50
vm.max_map_count = 262144

# 프로세스 및 스레드 최적화
kernel.pid_max = 4194304
kernel.threads-max = 1048576

# 커널 스케줄러 최적화
kernel.sched_migration_cost_ns = 5000000
kernel.sched_autogroup_enabled = 0
EOF

    # 설정 적용
    sysctl -p /etc/sysctl.d/99-kubernetes-performance.conf
    
    echo "Kernel parameters optimized"
}

# 시스템 리소스 제한 설정
configure_system_limits() {
    echo "Configuring system limits..."
    
    cat > /etc/security/limits.d/99-kubernetes.conf << 'EOF'
# Kubernetes 노드용 리소스 제한 설정
* soft nofile 1048576
* hard nofile 1048576
* soft nproc 1048576
* hard nproc 1048576
* soft core unlimited
* hard core unlimited
* soft memlock unlimited
* hard memlock unlimited

root soft nofile 1048576
root hard nofile 1048576
root soft nproc 1048576
root hard nproc 1048576
EOF

    # systemd 서비스 제한 설정
    mkdir -p /etc/systemd/system/kubelet.service.d
    cat > /etc/systemd/system/kubelet.service.d/20-limits.conf << 'EOF'
[Service]
LimitNOFILE=1048576
LimitNPROC=1048576
LimitMEMLOCK=infinity
EOF

    systemctl daemon-reload
    
    echo "System limits configured"
}

# CPU 거버너 및 성능 설정
optimize_cpu_performance() {
    echo "Optimizing CPU performance..."
    
    # CPU 거버너를 performance 모드로 설정
    for cpu in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do
        if [ -f "$cpu" ]; then
            echo performance > "$cpu"
        fi
    done
    
    # CPU 절전 기능 비활성화
    for cpu in /sys/devices/system/cpu/cpu*/cpuidle/state*/disable; do
        if [ -f "$cpu" ]; then
            echo 1 > "$cpu"
        fi
    done
    
    # NUMA 밸런싱 비활성화 (단일 NUMA 노드가 아닌 경우)
    echo 0 > /proc/sys/kernel/numa_balancing
    
    # 인터럽트 밸런싱 최적화
    if command -v irqbalance >/dev/null 2>&1; then
        systemctl enable irqbalance
        systemctl start irqbalance
    fi
    
    echo "CPU performance optimized"
}

# 디스크 I/O 최적화
optimize_disk_io() {
    echo "Optimizing disk I/O..."
    
    # SSD용 스케줄러 설정
    for disk in /sys/block/sd*/queue/scheduler; do
        if [ -f "$disk" ]; then
            echo noop > "$disk" 2>/dev/null || echo none > "$disk" 2>/dev/null
        fi
    done
    
    # NVMe용 설정
    for disk in /sys/block/nvme*/queue/scheduler; do
        if [ -f "$disk" ]; then
            echo none > "$disk" 2>/dev/null
        fi
    done
    
    # Read-ahead 설정
    for disk in /sys/block/sd*/queue/read_ahead_kb; do
        if [ -f "$disk" ]; then
            echo 128 > "$disk"
        fi
    done
    
    echo "Disk I/O optimized"
}

optimize_kernel_parameters
configure_system_limits
optimize_cpu_performance
optimize_disk_io
```

### kubelet 성능 최적화

```yaml
# kubelet-config-performance.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration

# 기본 설정
authentication:
  webhook:
    enabled: true
  anonymous:
    enabled: false

authorization:
  mode: Webhook

# 성능 최적화 설정
maxPods: 250  # 노드당 최대 Pod 수 (기본값: 110)

# 리소스 예약
systemReserved:
  cpu: "1000m"
  memory: "2Gi"
  ephemeral-storage: "10Gi"

kubeReserved:
  cpu: "500m"
  memory: "1Gi"
  ephemeral-storage: "5Gi"

# Eviction 임계값 최적화
evictionHard:
  memory.available: "500Mi"
  nodefs.available: "10%"
  nodefs.inodesFree: "5%"
  imagefs.available: "15%"

evictionSoft:
  memory.available: "1Gi"
  nodefs.available: "15%"
  nodefs.inodesFree: "10%"
  imagefs.available: "20%"

evictionSoftGracePeriod:
  memory.available: "2m"
  nodefs.available: "5m"
  nodefs.inodesFree: "5m"
  imagefs.available: "5m"

# 가비지 컬렉션 최적화
imageGCHighThresholdPercent: 85
imageGCLowThresholdPercent: 80

containerGCThreshold:
  minAge: 1m
  maxPerPodContainer: 2
  maxContainers: 240

# 동기화 주기 최적화
syncFrequency: 60s
nodeStatusUpdateFrequency: 10s
nodeStatusReportFrequency: 5m

# 볼륨 플러그인 최적화
volumeStatsAggPeriod: 60s

# 로그 설정
logging:
  format: json

# 네트워크 설정
clusterDNS:
  - "10.96.0.10"
clusterDomain: "cluster.local"

# CPU 관리 정책 (고성능 워크로드용)
cpuManagerPolicy: static
topologyManagerPolicy: single-numa-node

# 메모리 관리 정책
memoryManagerPolicy: Static

# 컨테이너 런타임 최적화
containerRuntimeEndpoint: "unix:///var/run/containerd/containerd.sock"
containerLogMaxSize: "50Mi"
containerLogMaxFiles: 5

# 읽기 전용 포트 비활성화 (보안)
readOnlyPort: 0

# 헬스체크 최적화
streamingConnectionIdleTimeout: 4h
nodeStatusMaxImages: 50

# 기타 최적화
serializeImagePulls: false  # 병렬 이미지 풀 허용
registryPullQPS: 10
registryBurst: 20
```

## 🌐 네트워크 성능 최적화

### CNI 플러그인 최적화

```yaml
# calico-performance-config.yaml
---
# Calico 성능 최적화 설정
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec:
  calicoNetwork:
    bgp: Enabled
    hostPorts: Enabled
    multiInterfaceMode: None
    containerIPForwarding: Enabled
    ipPools:
    - blockSize: 26
      cidr: 10.244.0.0/16
      encapsulation: VXLAN
      natOutgoing: Enabled
      nodeSelector: all()
  
  # 성능 최적화
  componentResources:
  - componentName: Node
    resourceRequirements:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi
  - componentName: Typha
    resourceRequirements:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi

---
# Felix 성능 튜닝
apiVersion: projectcalico.org/v3
kind: FelixConfiguration
metadata:
  name: default
spec:
  # 로그 레벨 조정
  logSeverityScreen: Info
  
  # 성능 관련 설정
  bpfEnabled: true  # eBPF 활성화 (지원되는 커널에서)
  bpfLogLevel: Off
  
  # iptables 최적화
  iptablesMarkMask: 0xffff0000
  iptablesPostWriteCheckIntervalSecs: 5
  iptablesRefreshInterval: 60s
  
  # 연결 추적 최적화
  genericXDPEnabled: true
  
  # 라우팅 최적화
  routeRefreshInterval: 60s
  interfaceRefreshInterval: 90s
  
  # 워크큐 크기 조정
  interfaceRefreshInterval: 90s
  routeRefreshInterval: 90s

---
# BGP 설정 최적화
apiVersion: projectcalico.org/v3
kind: BGPConfiguration
metadata:
  name: default
spec:
  logSeverityScreen: Info
  asNumber: 64512
  serviceClusterIPs:
  - cidr: 10.96.0.0/12
  serviceExternalIPs:
  - cidr: 192.168.100.0/24
```

### 네트워크 트래픽 최적화

```bash
#!/bin/bash
# network-optimization.sh

# 네트워크 인터페이스 최적화
optimize_network_interfaces() {
    echo "Optimizing network interfaces..."
    
    # 모든 네트워크 인터페이스에 대해 최적화 수행
    for interface in $(ip link show | grep -E '^[0-9]+:' | grep -v lo | awk -F': ' '{print $2}'); do
        echo "Optimizing interface: $interface"
        
        # 링 버퍼 크기 증가
        ethtool -G $interface rx 4096 tx 4096 2>/dev/null || true
        
        # TCP Segmentation Offload 활성화
        ethtool -K $interface tso on 2>/dev/null || true
        ethtool -K $interface gso on 2>/dev/null || true
        ethtool -K $interface gro on 2>/dev/null || true
        
        # Checksum offload 활성화
        ethtool -K $interface tx-checksumming on 2>/dev/null || true
        ethtool -K $interface rx-checksumming on 2>/dev/null || true
        
        # Scatter-gather 활성화
        ethtool -K $interface sg on 2>/dev/null || true
    done
    
    echo "Network interfaces optimized"
}

# iptables 성능 최적화
optimize_iptables() {
    echo "Optimizing iptables..."
    
    # iptables 모듈 최적화
    modprobe nf_conntrack
    
    # 연결 추적 테이블 크기 증가
    echo 1048576 > /proc/sys/net/netfilter/nf_conntrack_max
    echo 262144 > /proc/sys/net/netfilter/nf_conntrack_buckets
    
    # 연결 추적 시간 초과 최적화
    echo 600 > /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_established
    echo 120 > /proc/sys/net/netfilter/nf_conntrack_tcp_timeout_time_wait
    
    # 영구 설정
    cat >> /etc/sysctl.d/99-netfilter.conf << 'EOF'
net.netfilter.nf_conntrack_max = 1048576
net.netfilter.nf_conntrack_buckets = 262144
net.netfilter.nf_conntrack_tcp_timeout_established = 600
net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120
EOF
    
    echo "iptables optimized"
}

# 네트워크 큐 최적화
optimize_network_queues() {
    echo "Optimizing network queues..."
    
    # 멀티큐 네트워크 인터페이스 최적화
    for interface in $(ip link show | grep -E '^[0-9]+:' | grep -v lo | awk -F': ' '{print $2}'); do
        # RSS (Receive Side Scaling) 최적화
        cpu_count=$(nproc)
        queue_count=$(ethtool -l $interface 2>/dev/null | grep -A1 "Current hardware settings" | tail -1 | awk '{print $2}' || echo 1)
        
        if [ "$queue_count" -gt 1 ]; then
            echo "Setting up RSS for $interface with $queue_count queues"
            ethtool -X $interface equal $queue_count 2>/dev/null || true
        fi
        
        # 인터럽트 어피니티 설정
        interface_irqs=$(grep $interface /proc/interrupts | awk '{print $1}' | sed 's/:$//')
        cpu_id=0
        for irq in $interface_irqs; do
            echo $((1 << cpu_id)) > /proc/irq/$irq/smp_affinity 2>/dev/null || true
            cpu_id=$(((cpu_id + 1) % cpu_count))
        done
    done
    
    echo "Network queues optimized"
}

optimize_network_interfaces
optimize_iptables
optimize_network_queues
```

## 💾 스토리지 성능 최적화

### 컨테이너 런타임 최적화

```toml
# /etc/containerd/config.toml
version = 2

[grpc]
  tcp_address = ""
  tcp_tls_cert = ""
  tcp_tls_key = ""
  uid = 0
  gid = 0
  max_recv_message_size = 16777216
  max_send_message_size = 16777216

[debug]
  address = ""
  uid = 0
  gid = 0
  level = ""

[metrics]
  address = "127.0.0.1:1338"
  grpc_histogram = false

[cgroup]
  path = ""

[timeouts]
  "io.containerd.timeout.shim.cleanup" = "5s"
  "io.containerd.timeout.shim.load" = "5s"
  "io.containerd.timeout.shim.shutdown" = "3s"
  "io.containerd.timeout.task.state" = "2s"

[plugins]
  [plugins."io.containerd.gc.v1.scheduler"]
    pause_threshold = 0.02
    deletion_threshold = 0
    mutation_threshold = 100
    schedule_delay = "0s"
    startup_delay = "100ms"
    
  [plugins."io.containerd.grpc.v1.cri"]
    device_ownership_from_security_context = false
    disable_apparmor = false
    disable_cgroup = false
    disable_hugetlb_controller = true
    disable_proc_mount = false
    disable_tcp_service = true
    enable_selinux = false
    enable_tls_streaming = false
    max_concurrent_downloads = 10  # 동시 다운로드 증가
    max_container_log_line_size = 16384
    restrict_oom_score_adj = false
    sandbox_image = "k8s.gcr.io/pause:3.7"
    selinux_category_range = 1024
    stats_collect_period = 10
    stream_idle_timeout = "4h0m0s"
    stream_server_address = "127.0.0.1"
    stream_server_port = "0"
    systemd_cgroup = true  # systemd cgroup 드라이버 사용
    tolerate_missing_hugetlb_controller = true
    unset_seccomp_profile = ""

    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "/opt/cni/bin"
      conf_dir = "/etc/cni/net.d"
      conf_template = ""
      max_conf_num = 1

    [plugins."io.containerd.grpc.v1.cri".containerd]
      default_runtime_name = "runc"
      no_pivot = false
      snapshotter = "overlayfs"
      
      # 이미지 풀 최적화
      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
          runtime_type = "io.containerd.runc.v2"
          runtime_engine = ""
          runtime_root = ""
          privileged_without_host_devices = false
          base_runtime_spec = ""
          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
            SystemdCgroup = true
            BinaryName = ""

    [plugins."io.containerd.grpc.v1.cri".image_decryption]
      key_model = ""

    [plugins."io.containerd.grpc.v1.cri".registry]
      [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
        [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
          endpoint = ["https://registry-1.docker.io"]

  [plugins."io.containerd.internal.v1.opt"]
    path = "/opt/containerd"

  [plugins."io.containerd.internal.v1.restart"]
    interval = "10s"

  [plugins."io.containerd.metadata.v1.bolt"]
    content_sharing_policy = "shared"

  [plugins."io.containerd.monitor.v1.cgroups"]
    no_prometheus = false

  [plugins."io.containerd.runtime.v1.linux"]
    no_shim = false
    runtime = "runc"
    runtime_root = ""
    shim = "containerd-shim"
    shim_debug = false

  [plugins."io.containerd.runtime.v2.task"]
    platforms = ["linux/amd64"]

  [plugins."io.containerd.service.v1.diff-service"]
    default = ["walking"]

  [plugins."io.containerd.snapshotter.v1.devmapper"]
    pool_name = ""
    root_path = ""
    base_image_size = ""
    async_remove = false
```

## 📊 성능 모니터링과 분석

### 종합 성능 모니터링 스크립트

```bash
#!/bin/bash
# performance-monitoring.sh

# 성능 메트릭 수집
collect_performance_metrics() {
    echo "=== Kubernetes Performance Metrics ==="
    echo "Timestamp: $(date)"
    echo
    
    # 클러스터 전체 리소스 사용량
    echo "=== Cluster Resource Usage ==="
    kubectl top nodes --sort-by=cpu
    echo
    
    # 네임스페이스별 리소스 사용량
    echo "=== Top Resource Consuming Pods ==="
    kubectl top pods --all-namespaces --sort-by=cpu | head -20
    echo
    
    # API Server 지연시간 확인
    echo "=== API Server Latency ==="
    time kubectl get nodes >/dev/null
    echo
    
    # etcd 성능 메트릭
    echo "=== etcd Performance ==="
    if command -v etcdctl >/dev/null; then
        ETCDCTL_API=3 etcdctl \
            --endpoints=https://127.0.0.1:2379 \
            --cacert=/etc/kubernetes/pki/etcd/ca.crt \
            --cert=/etc/kubernetes/pki/etcd/server.crt \
            --key=/etc/kubernetes/pki/etcd/server.key \
            endpoint status --write-out=table 2>/dev/null || echo "etcd not accessible"
    fi
    echo
    
    # 시스템 리소스 상태
    echo "=== System Resources ==="
    echo "Load Average: $(uptime | awk -F'load average:' '{print $2}')"
    echo "Memory Usage: $(free | grep Mem | awk '{printf "%.1f%%", $3/$2 * 100.0}')"
    echo "Disk Usage:"
    df -h | grep -E '(Filesystem|/dev/)' | grep -v tmpfs
    echo
    
    # 네트워크 상태
    echo "=== Network Statistics ==="
    ss -tuln | grep -E ':(6443|2379|2380|10250|10251|10252)' | wc -l | xargs echo "Active Kubernetes Connections:"
    
    # 컨테이너 런타임 상태
    echo "=== Container Runtime Status ==="
    systemctl is-active containerd
    crictl info | grep -E "(runtimeVersion|osType)"
}

# 성능 병목 지점 분석
analyze_performance_bottlenecks() {
    echo "=== Performance Bottleneck Analysis ==="
    
    # CPU 사용률이 높은 프로세스
    echo "Top CPU consuming processes:"
    ps aux --sort=-%cpu | head -10
    echo
    
    # 메모리 사용률이 높은 프로세스
    echo "Top Memory consuming processes:"
    ps aux --sort=-%mem | head -10
    echo
    
    # I/O 대기 시간 확인
    echo "I/O Wait Statistics:"
    iostat -x 1 1 | tail -n +4 2>/dev/null || echo "iostat not available"
    echo
    
    # 네트워크 연결 상태
    echo "Network Connection Statistics:"
    ss -s
    echo
    
    # 컨텍스트 스위치 확인
    echo "Context Switches per second:"
    vmstat 1 2 | tail -1 | awk '{print "cs: " $12 ", in: " $11}'
}

# 성능 개선 권장사항 생성
generate_performance_recommendations() {
    echo "=== Performance Recommendations ==="
    
    # CPU 사용률 분석
    cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | sed 's/%us,//')
    if (( $(echo "$cpu_usage > 80" | bc -l) )); then
        echo "⚠️  HIGH CPU USAGE ($cpu_usage%) detected"
        echo "   - Consider scaling out workloads"
        echo "   - Review CPU requests/limits"
        echo "   - Check for CPU-intensive processes"
    fi
    
    # 메모리 사용률 분석
    mem_usage=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')
    if (( $(echo "$mem_usage > 80" | bc -l) )); then
        echo "⚠️  HIGH MEMORY USAGE ($mem_usage%) detected"
        echo "   - Consider adding more nodes"
        echo "   - Review memory requests/limits"
        echo "   - Check for memory leaks"
    fi
    
    # 디스크 사용률 분석
    disk_usage=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
    if [ "$disk_usage" -gt 85 ]; then
        echo "⚠️  HIGH DISK USAGE ($disk_usage%) detected"
        echo "   - Clean up old logs and images"
        echo "   - Consider adding storage"
        echo "   - Review data retention policies"
    fi
    
    # 네트워크 분석
    tcp_connections=$(ss -t | wc -l)
    if [ "$tcp_connections" -gt 10000 ]; then
        echo "⚠️  HIGH TCP CONNECTIONS ($tcp_connections) detected"
        echo "   - Review connection pooling"
        echo "   - Check for connection leaks"
        echo "   - Consider increasing connection limits"
    fi
}

# 성능 보고서 생성
generate_performance_report() {
    local report_file="/var/log/k8s-performance-$(date +%Y%m%d_%H%M%S).log"
    
    {
        collect_performance_metrics
        echo
        analyze_performance_bottlenecks
        echo
        generate_performance_recommendations
    } | tee "$report_file"
    
    echo "Performance report generated: $report_file"
}

case "${1:-collect}" in
    collect)
        collect_performance_metrics
        ;;
    analyze)
        analyze_performance_bottlenecks
        ;;
    recommend)
        generate_performance_recommendations
        ;;
    report)
        generate_performance_report
        ;;
    *)
        echo "Usage: $0 {collect|analyze|recommend|report}"
        exit 1
        ;;
esac
```

## 🎚️ 워크로드별 성능 최적화

### 데이터베이스 워크로드 최적화

```yaml
# database-performance-optimization.yaml
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-optimized
spec:
  serviceName: mysql
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      # 고성능 노드에 스케줄링
      nodeSelector:
        performance-tier: high
        storage-type: ssd
      
      # 리소스 요청/제한 최적화
      containers:
      - name: mysql
        image: mysql:8.0
        resources:
          requests:
            cpu: "2000m"
            memory: "4Gi"
          limits:
            cpu: "4000m"
            memory: "8Gi"
        
        # 환경 변수 최적화
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        
        # MySQL 설정 최적화
        volumeMounts:
        - name: mysql-config
          mountPath: /etc/mysql/conf.d
        - name: mysql-data
          mountPath: /var/lib/mysql
        
        # 보안 컨텍스트
        securityContext:
          runAsUser: 999
          runAsGroup: 999
          allowPrivilegeEscalation: false
          
      volumes:
      - name: mysql-config
        configMap:
          name: mysql-config
  
  volumeClaimTemplates:
  - metadata:
      name: mysql-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-ssd  # 고성능 스토리지 클래스
      resources:
        requests:
          storage: 100Gi

---
# MySQL 성능 최적화 설정
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
data:
  my.cnf: |
    [mysqld]
    # 기본 설정
    bind-address = 0.0.0.0
    port = 3306
    
    # 성능 최적화
    innodb_buffer_pool_size = 6G  # 전체 메모리의 75%
    innodb_log_file_size = 1G
    innodb_log_buffer_size = 64M
    innodb_flush_log_at_trx_commit = 2
    innodb_file_per_table = 1
    innodb_open_files = 4000
    
    # 연결 최적화
    max_connections = 1000
    max_connect_errors = 10000
    wait_timeout = 300
    interactive_timeout = 300
    
    # 쿼리 캐시
    query_cache_type = 1
    query_cache_size = 256M
    query_cache_limit = 2M
    
    # 테이블 캐시
    table_open_cache = 4000
    table_definition_cache = 2000
    
    # 스레드 설정
    thread_cache_size = 256
    thread_stack = 256K
    
    # 네트워크 최적화
    max_allowed_packet = 128M
    net_buffer_length = 32K
```

### 웹 애플리케이션 최적화

```yaml
# web-app-performance-optimization.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app-optimized
spec:
  replicas: 6
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      # 파드 분산 배치
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web-app
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: web-app
        image: nginx:1.21-alpine
        
        # 리소스 최적화
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        
        # 포트 설정
        ports:
        - containerPort: 8080
          name: http
        
        # 헬스체크 최적화
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
          
        # 환경별 설정
        env:
        - name: NGINX_WORKER_PROCESSES
          value: "auto"
        - name: NGINX_WORKER_CONNECTIONS
          value: "1024"
        
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/conf.d
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /var/cache/nginx
        - name: run
          mountPath: /var/run
          
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
      - name: run
        emptyDir: {}

---
# HPA 설정
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app-optimized
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

## 📋 성능 최적화 체크리스트

### 클러스터 레벨
- [ ] etcd 압축 및 조각 모음 정기 실행
- [ ] API Server 리소스 제한 적절히 설정
- [ ] Controller Manager/Scheduler 최적화
- [ ] 불필요한 애드온 제거

### 노드 레벨
- [ ] 커널 파라미터 최적화
- [ ] CPU 거버너 performance 모드 설정
- [ ] 시스템 리소스 예약 설정
- [ ] 디스크 I/O 스케줄러 최적화
- [ ] 네트워크 인터페이스 최적화

### 애플리케이션 레벨
- [ ] 적절한 리소스 요청/제한 설정
- [ ] HPA/VPA 설정
- [ ] 파드 어피니티/안티어피니티 적용
- [ ] 헬스체크 최적화
- [ ] 이미지 크기 최소화

### 스토리지 레벨
- [ ] 워크로드에 적합한 스토리지 클래스 선택
- [ ] 고성능 워크로드에 Local SSD 사용
- [ ] 스토리지 성능 모니터링
- [ ] 백업 전략 최적화

---

> 💡 **실전 경험**: 성능 최적화는 점진적으로 진행하세요. 한 번에 모든 설정을 변경하면 문제의 원인을 파악하기 어려워집니다. 각 변경사항의 효과를 측정하고 검증한 후 다음 단계로 진행하는 것이 중요합니다. 특히 온프렘 환경에서는 하드웨어 특성을 잘 이해하고 그에 맞는 최적화를 적용해야 합니다.

태그: #performance #tuning #optimization #monitoring #onprem
