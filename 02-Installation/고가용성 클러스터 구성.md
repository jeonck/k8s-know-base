# 고가용성 클러스터 구성

## 🎯 개요

온프렘 환경에서 단일 장애점을 제거하고 높은 가용성을 보장하는 쿠버네티스 클러스터 구성 방법을 다룹니다. 실제 운영 환경에서 검증된 HA 패턴을 제시합니다.

## 🏗️ HA 아키텍처 설계

### 권장 HA 구성

```
                    ┌─────────────────┐
                    │  Load Balancer  │
                    │   (HAProxy)     │
                    │  VIP: 10.1.1.100│
                    └────────┬────────┘
                             │
           ┌─────────────────┼─────────────────┐
           │                 │                 │
    ┌──────▼──────┐   ┌──────▼──────┐   ┌──────▼──────┐
    │   Master 1  │   │   Master 2  │   │   Master 3  │
    │ 10.1.1.101  │   │ 10.1.1.102  │   │ 10.1.1.103  │
    │             │   │             │   │             │
    │ API Server  │   │ API Server  │   │ API Server  │
    │ Controller  │   │ Controller  │   │ Controller  │
    │ Scheduler   │   │ Scheduler   │   │ Scheduler   │
    │ etcd        │   │ etcd        │   │ etcd        │
    └─────────────┘   └─────────────┘   └─────────────┘
           │                 │                 │
           └─────────────────┼─────────────────┘
                             │
        ┌────────────────────┼────────────────────┐
        │                    │                    │
 ┌──────▼──────┐      ┌──────▼──────┐      ┌──────▼──────┐
 │  Worker 1   │      │  Worker 2   │      │  Worker N   │
 │ 10.1.1.201  │      │ 10.1.1.202  │      │ 10.1.1.20N │
 └─────────────┘      └─────────────┘      └─────────────┘
```

### 네트워크 설계

```yaml
# 네트워크 세그먼트 계획
관리 네트워크: 10.1.1.0/24
  - 로드밸런서 VIP: 10.1.1.100
  - 마스터 노드: 10.1.1.101-103
  - 워커 노드: 10.1.1.201-250

클러스터 네트워크: 10.244.0.0/16 (Pod CIDR)
서비스 네트워크: 10.96.0.0/12 (Service CIDR)

스토리지 네트워크: 10.2.1.0/24 (선택사항)
  - 스토리지 서버: 10.2.1.101-110
  - iSCSI/NFS 전용
```

## ⚖️ 로드밸런서 구성

### HAProxy 설정

```bash
# HAProxy 설치 (각 LB 노드에서)
yum install -y haproxy keepalived

# HAProxy 설정 파일
cat > /etc/haproxy/haproxy.cfg << 'EOF'
global
    log         127.0.0.1:514 local0
    chroot      /var/lib/haproxy
    stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user        haproxy
    group       haproxy
    daemon

defaults
    mode                    tcp
    log                     global
    option                  tcplog
    option                  dontlognull
    option                  redispatch
    retries                 3
    timeout queue           1m
    timeout connect         10s
    timeout client          1m
    timeout server          1m
    timeout check           10s
    maxconn                 3000

# Statistics
frontend stats
    bind *:9000
    mode http
    stats enable
    stats uri /stats
    stats refresh 10s
    stats admin if TRUE

# Kubernetes API Server Frontend
frontend k8s-api
    bind 10.1.1.100:6443
    mode tcp
    option tcplog
    default_backend k8s-api-backend

# Kubernetes API Server Backend
backend k8s-api-backend
    mode tcp
    option tcplog
    option tcp-check
    balance roundrobin
    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
    
    server master1 10.1.1.101:6443 check
    server master2 10.1.1.102:6443 check
    server master3 10.1.1.103:6443 check

# HTTP Ingress Frontend (optional)
frontend ingress-http
    bind 10.1.1.100:80
    mode http
    option httplog
    default_backend ingress-http-backend

# HTTPS Ingress Frontend (optional)
frontend ingress-https
    bind 10.1.1.100:443
    mode tcp
    option tcplog
    default_backend ingress-https-backend

# HTTP Ingress Backend
backend ingress-http-backend
    mode http
    option httplog
    balance roundrobin
    option httpchk GET /healthz
    
    server worker1 10.1.1.201:30080 check
    server worker2 10.1.1.202:30080 check
    server worker3 10.1.1.203:30080 check

# HTTPS Ingress Backend
backend ingress-https-backend
    mode tcp
    option tcplog
    balance roundrobin
    
    server worker1 10.1.1.201:30443 check
    server worker2 10.1.1.202:30443 check
    server worker3 10.1.1.203:30443 check
EOF
```

### Keepalived 설정 (VIP 관리)

```bash
# Keepalived 설정 (Primary LB)
cat > /etc/keepalived/keepalived.conf << 'EOF'
vrrp_script chk_haproxy {
    script "/bin/kill -0 `cat /var/run/haproxy.pid`"
    interval 2
    weight 2
    fall 3
    rise 2
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 110
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass mypassword
    }
    virtual_ipaddress {
        10.1.1.100
    }
    track_script {
        chk_haproxy
    }
}
EOF

# Keepalived 설정 (Backup LB) - priority를 100으로 설정
# state를 BACKUP으로 변경
```

### 로드밸런서 서비스 시작

```bash
# 서비스 활성화 및 시작
systemctl enable haproxy keepalived
systemctl start haproxy keepalived

# 상태 확인
systemctl status haproxy keepalived

# VIP 확인
ip addr show | grep 10.1.1.100

# HAProxy 통계 확인
curl http://10.1.1.100:9000/stats
```

## 🎛️ etcd 클러스터 설정

### etcd 클러스터 구성

```bash
# 각 마스터 노드에서 etcd 클러스터 설정
# kubeadm-config.yaml에 etcd 설정 포함

cat > /root/kubeadm-config.yaml << 'EOF'
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.1.1.101  # 각 노드별로 변경
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: v1.28.0
clusterName: ha-cluster
controlPlaneEndpoint: "10.1.1.100:6443"  # LB VIP
networking:
  serviceSubnet: "10.96.0.0/12"
  podSubnet: "10.244.0.0/16"
  dnsDomain: "cluster.local"
apiServer:
  advertiseAddress: 10.1.1.101  # 각 노드별로 변경
  certSANs:
  - "10.1.1.100"  # LB VIP
  - "10.1.1.101"  # Master 1
  - "10.1.1.102"  # Master 2
  - "10.1.1.103"  # Master 3
  - "k8s-api.company.local"
  extraArgs:
    audit-log-maxage: "30"
    audit-log-maxbackup: "3"
    audit-log-maxsize: "100"
    audit-log-path: "/var/log/audit.log"
etcd:
  local:
    serverCertSANs:
    - "10.1.1.101"
    - "10.1.1.102" 
    - "10.1.1.103"
    peerCertSANs:
    - "10.1.1.101"
    - "10.1.1.102"
    - "10.1.1.103"
    extraArgs:
      initial-cluster: "master1=https://10.1.1.101:2380,master2=https://10.1.1.102:2380,master3=https://10.1.1.103:2380"
      initial-cluster-state: "new"
      name: "master1"  # 각 노드별로 변경
      listen-peer-urls: "https://10.1.1.101:2380"  # 각 노드별로 변경
      listen-client-urls: "https://10.1.1.101:2379,https://127.0.0.1:2379"  # 각 노드별로 변경
      advertise-client-urls: "https://10.1.1.101:2379"  # 각 노드별로 변경
      initial-advertise-peer-urls: "https://10.1.1.101:2380"  # 각 노드별로 변경
EOF
```

### 첫 번째 마스터 노드 초기화

```bash
# 첫 번째 마스터 노드에서 클러스터 초기화
kubeadm init --config=/root/kubeadm-config.yaml --upload-certs

# 출력에서 join 명령어 저장
# 마스터 노드 join 명령어:
kubeadm join 10.1.1.100:6443 --token <token> \
    --discovery-token-ca-cert-hash sha256:<hash> \
    --control-plane --certificate-key <cert-key>

# 워커 노드 join 명령어:
kubeadm join 10.1.1.100:6443 --token <token> \
    --discovery-token-ca-cert-hash sha256:<hash>
```

### 추가 마스터 노드 조인

```bash
# 두 번째, 세 번째 마스터 노드에서 실행
# kubeadm-config.yaml 파일을 각 노드의 IP에 맞게 수정 후

kubeadm join 10.1.1.100:6443 --token <token> \
    --discovery-token-ca-cert-hash sha256:<hash> \
    --control-plane --certificate-key <cert-key>

# kubectl 설정
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

## 🔧 HA 검증 및 테스트

### 클러스터 상태 확인

```bash
# 노드 상태 확인
kubectl get nodes -o wide

# etcd 클러스터 상태 확인
kubectl exec -n kube-system etcd-master1 -- etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  member list

# API 서버 상태 확인
kubectl get componentstatuses
```

### 장애 시나리오 테스트

```bash
# 1. 마스터 노드 1대 중단 테스트
sudo systemctl stop kubelet
# 클러스터 API 접근성 확인
kubectl get nodes

# 2. etcd 1대 중단 테스트
sudo systemctl stop etcd
# 클러스터 상태 확인
kubectl get pods -A

# 3. 로드밸런서 failover 테스트
sudo systemctl stop haproxy  # Primary LB에서
# VIP가 Backup LB로 이동하는지 확인
```

### 자동 복구 확인

```bash
# 서비스 재시작 후 자동 복구 확인
sudo systemctl start kubelet
sudo systemctl start etcd
sudo systemctl start haproxy

# 클러스터 상태 정상화 확인
kubectl get nodes
kubectl get pods -A
```

## 📊 HA 모니터링

### etcd 모니터링

```yaml
# etcd-monitoring.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: etcd-monitoring
  namespace: monitoring
spec:
  selector:
    matchLabels:
      component: etcd
  endpoints:
  - port: http-metrics
    interval: 30s
    scheme: https
    tlsConfig:
      caFile: /etc/prometheus/secrets/etcd-certs/ca.crt
      certFile: /etc/prometheus/secrets/etcd-certs/client.crt
      keyFile: /etc/prometheus/secrets/etcd-certs/client.key
      serverName: localhost
      insecureSkipVerify: false

---
# etcd 알림 규칙
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: etcd-alerts
  namespace: monitoring
spec:
  groups:
  - name: etcd
    rules:
    - alert: EtcdMemberDown
      expr: up{job="etcd"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "etcd member is down"
        description: "etcd member {{ $labels.instance }} is down for more than 5 minutes."
        
    - alert: EtcdHighCommitDurations
      expr: histogram_quantile(0.99, sum(rate(etcd_disk_backend_commit_duration_seconds_bucket[5m])) by (instance, le)) > 0.25
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "etcd high commit durations"
        description: "etcd commit durations are high on {{ $labels.instance }}"
```

### HAProxy 모니터링

```bash
# HAProxy Exporter 설치
docker run -d \
  --name haproxy-exporter \
  -p 9101:9101 \
  quay.io/prometheus/haproxy-exporter:latest \
  --haproxy.scrape-uri="http://10.1.1.100:9000/stats;csv"

# Prometheus에서 HAProxy 메트릭 수집 설정
# prometheus.yml에 추가:
# - job_name: 'haproxy'
#   static_configs:
#   - targets: ['10.1.1.100:9101']
```

## 🛠️ HA 운영 베스트 프랙티스

### 정기 백업 전략

```bash
#!/bin/bash
# ha-backup.sh - HA 클러스터 백업 스크립트

BACKUP_DIR="/var/backups/ha-cluster"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p "$BACKUP_DIR"

# etcd 백업 (모든 마스터에서)
for master in master1 master2 master3; do
    echo "Backing up etcd from $master..."
    ssh "$master" "
        ETCDCTL_API=3 etcdctl snapshot save /tmp/etcd-snapshot-$DATE.db \
          --endpoints=https://127.0.0.1:2379 \
          --cacert=/etc/kubernetes/pki/etcd/ca.crt \
          --cert=/etc/kubernetes/pki/etcd/server.crt \
          --key=/etc/kubernetes/pki/etcd/server.key
    "
    scp "$master:/tmp/etcd-snapshot-$DATE.db" "$BACKUP_DIR/etcd-$master-$DATE.db"
    ssh "$master" "rm /tmp/etcd-snapshot-$DATE.db"
done

# 쿠버네티스 설정 백업
kubectl get all --all-namespaces -o yaml > "$BACKUP_DIR/k8s-resources-$DATE.yaml"

# HAProxy 설정 백업
for lb in lb1 lb2; do
    scp "$lb:/etc/haproxy/haproxy.cfg" "$BACKUP_DIR/haproxy-$lb-$DATE.cfg"
    scp "$lb:/etc/keepalived/keepalived.conf" "$BACKUP_DIR/keepalived-$lb-$DATE.conf"
done

echo "HA cluster backup completed: $BACKUP_DIR"
```

### 업그레이드 절차

```bash
#!/bin/bash
# ha-upgrade.sh - HA 클러스터 업그레이드 스크립트

KUBE_VERSION="v1.28.1"

echo "Starting HA cluster upgrade to $KUBE_VERSION..."

# 1. 백업 실행
./ha-backup.sh

# 2. 첫 번째 마스터 노드 업그레이드
echo "Upgrading first master node..."
kubectl drain master1 --ignore-daemonsets
ssh master1 "
    sudo kubeadm upgrade plan
    sudo kubeadm upgrade apply $KUBE_VERSION -y
    sudo yum update -y kubelet kubeadm kubectl
    sudo systemctl daemon-reload
    sudo systemctl restart kubelet
"
kubectl uncordon master1

# 3. 나머지 마스터 노드 업그레이드
for master in master2 master3; do
    echo "Upgrading $master..."
    kubectl drain "$master" --ignore-daemonsets
    ssh "$master" "
        sudo kubeadm upgrade node
        sudo yum update -y kubelet kubeadm kubectl
        sudo systemctl daemon-reload
        sudo systemctl restart kubelet
    "
    kubectl uncordon "$master"
done

# 4. 워커 노드 업그레이드 (순차적으로)
for worker in worker1 worker2 worker3; do
    echo "Upgrading $worker..."
    kubectl drain "$worker" --ignore-daemonsets --delete-emptydir-data
    ssh "$worker" "
        sudo yum update -y kubelet kubeadm kubectl
        sudo systemctl daemon-reload
        sudo systemctl restart kubelet
    "
    kubectl uncordon "$worker"
done

echo "HA cluster upgrade completed!"
```

### 장애 복구 절차

```bash
#!/bin/bash
# disaster-recovery.sh

recover_etcd_member() {
    local failed_member=$1
    
    echo "Recovering etcd member: $failed_member"
    
    # 1. 실패한 멤버 제거
    kubectl exec -n kube-system etcd-master1 -- etcdctl \
      --endpoints=https://127.0.0.1:2379 \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      member remove "$failed_member"
    
    # 2. 새 멤버 추가
    kubectl exec -n kube-system etcd-master1 -- etcdctl \
      --endpoints=https://127.0.0.1:2379 \
      --cacert=/etc/kubernetes/pki/etcd/ca.crt \
      --cert=/etc/kubernetes/pki/etcd/server.crt \
      --key=/etc/kubernetes/pki/etcd/server.key \
      member add "$failed_member" --peer-urls="https://$failed_member:2380"
    
    # 3. 노드에서 etcd 재시작
    ssh "$failed_member" "
        sudo systemctl stop etcd
        sudo rm -rf /var/lib/etcd/member
        sudo systemctl start etcd
    "
    
    echo "etcd member recovery completed"
}

# 사용 예: recover_etcd_member "10.1.1.102"
```

## 🚨 HA 트러블슈팅

### 일반적인 문제들

#### 1. Split-brain 현상
```bash
# etcd 클러스터 상태 확인
kubectl exec -n kube-system etcd-master1 -- etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  endpoint status --write-out=table

# 네트워크 분할 확인
ping -c 3 10.1.1.102
ping -c 3 10.1.1.103
```

#### 2. 로드밸런서 VIP 문제
```bash
# VIP 상태 확인
ip addr show | grep 10.1.1.100

# Keepalived 로그 확인
journalctl -u keepalived -f

# HAProxy 백엔드 상태 확인
curl http://10.1.1.100:9000/stats
```

#### 3. 인증서 문제
```bash
# 인증서 만료 확인
kubeadm certs check-expiration

# 인증서 갱신
kubeadm certs renew all
systemctl restart kubelet
```

---

> 💡 **실전 경험**: HA 구성에서 가장 중요한 것은 네트워크 안정성입니다. 특히 etcd 간 통신이 불안정하면 전체 클러스터가 영향을 받으므로, 전용 네트워크나 본딩을 고려하세요. 정기적인 장애 시나리오 테스트도 필수입니다.

태그: #ha #high-availability #etcd #loadbalancer #haproxy #onprem