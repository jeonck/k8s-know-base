# 온프렘 설치 전략

## 🎯 설치 방법 비교

### 설치 도구별 특징

| 방법 | 복잡도 | 고가용성 | 운영 편의성 | 온프렘 적합성 |
|------|--------|----------|-------------|---------------|
| kubeadm | 중간 | ✅ | 중간 | ⭐⭐⭐⭐⭐ |
| kops | 높음 | ✅ | 높음 | ⭐⭐⭐ |
| kubespray | 높음 | ✅ | 높음 | ⭐⭐⭐⭐ |
| 바이너리 설치 | 매우 높음 | ✅ | 낮음 | ⭐⭐ |
| Rancher | 낮음 | ✅ | 매우 높음 | ⭐⭐⭐⭐ |

## 🏗️ 권장 아키텍처

### 소규모 환경 (개발/테스트)
```
┌─────────────────────────────────┐
│     Single Master Node          │
│  ┌─────────┐ ┌─────────────────┐│
│  │API+etcd │ │ Controller +    ││
│  │+Sched   │ │ Scheduler       ││
│  └─────────┘ └─────────────────┘│
└─────────────────────────────────┘
         │
    ┌────┼────┐
┌───▼───┐┌───▼───┐
│Worker1││Worker2│
└───────┘└───────┘
```

**특징**:
- 마스터 1대 + 워커 2대 이상
- 비용 효율적
- 단일 장애점 존재

### 중규모 환경 (운영)
```
     ┌─────────────────┐
     │  Load Balancer  │
     │   (HAProxy)     │
     └────────┬────────┘
              │
    ┌─────────┼─────────┐
    │         │         │
┌───▼───┐ ┌──▼────┐ ┌──▼────┐
│Master1│ │Master2│ │Master3│
│       │ │       │ │       │
│ etcd  │ │ etcd  │ │ etcd  │
└───────┘ └───────┘ └───────┘
    │         │         │
    └─────────┼─────────┘
              │
  ┌───────────┼───────────┐
  │           │           │
┌─▼──┐    ┌──▼──┐    ┌──▼──┐
│WN1 │    │ WN2 │    │ WN3 │
└────┘    └─────┘    └─────┘
```

**특징**:
- 마스터 3대 (홀수 개)
- 고가용성 보장
- 추천 구성

### 대규모 환경 (엔터프라이즈)
```
┌─────────────────────────────────────┐
│         External Load Balancer      │
│            (F5/NetScaler)           │
└─────────────────┬───────────────────┘
                  │
      ┌───────────┼───────────┐
      │           │           │
  ┌───▼───┐   ┌──▼────┐   ┌──▼────┐
  │Master1│   │Master2│   │Master3│
  └───────┘   └───────┘   └───────┘
      │           │           │
  ┌───▼───┐   ┌──▼────┐   ┌──▼────┐
  │ etcd1 │   │ etcd2 │   │ etcd3 │
  └───────┘   └───────┘   └───────┘
                  │
    ┌─────────────┼─────────────┐
    │             │             │
┌───▼──┐      ┌──▼───┐      ┌──▼───┐
│Zone A│      │Zone B│      │Zone C│
│WN1-10│      │WN11-20│     │WN21-30│
└──────┘      └──────┘      └──────┘
```

**특징**:
- 컨트롤 플레인과 etcd 분리
- 멀티 존 구성
- 대규모 워커 노드

## 🔧 설치 전 준비사항

### 하드웨어 요구사항

#### 최소 요구사항
```yaml
마스터 노드:
  CPU: 2 cores
  RAM: 4GB
  Storage: 50GB
  Network: 1Gbps

워커 노드:
  CPU: 2 cores
  RAM: 4GB
  Storage: 50GB
  Network: 1Gbps
```

#### 운영 권장사항
```yaml
마스터 노드:
  CPU: 4-8 cores
  RAM: 8-16GB
  Storage: 100GB SSD
  Network: 1-10Gbps

워커 노드:
  CPU: 8+ cores
  RAM: 16-64GB
  Storage: 200GB+ SSD
  Network: 1-10Gbps
```

### 네트워크 설계

#### IP 주소 계획
```yaml
# 예시 네트워크 계획
Management Network: 192.168.1.0/24
  - 마스터 노드: 192.168.1.10-19
  - 워커 노드: 192.168.1.20-99
  - 로드밸런서: 192.168.1.5

Pod CIDR: 10.244.0.0/16
Service CIDR: 10.96.0.0/12
```

#### 필수 포트 오픈

**마스터 노드**:
```bash
# API Server
6443/tcp

# etcd
2379-2380/tcp

# Kubelet API
10250/tcp

# Scheduler
10251/tcp

# Controller Manager
10252/tcp
```

**워커 노드**:
```bash
# Kubelet API
10250/tcp

# NodePort Services
30000-32767/tcp
```

### 운영체제 설정

#### CentOS/RHEL 설정
```bash
# SELinux 비활성화
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# 방화벽 설정 (선택적)
systemctl disable firewalld
systemctl stop firewalld

# swap 비활성화
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# 브리지 네트워크 설정
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system
```

#### Ubuntu 설정
```bash
# UFW 비활성화 (선택적)
ufw disable

# swap 비활성화
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# 필수 모듈 로드
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

# sysctl 설정
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF
sysctl --system
```

## 🐳 컨테이너 런타임 설치

### containerd 설치 (권장)

#### CentOS/RHEL
```bash
# Docker 저장소 추가
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# containerd 설치
yum install -y containerd.io

# 설정 파일 생성
mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

# systemd cgroup 드라이버 설정
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml

# 서비스 시작
systemctl enable containerd
systemctl start containerd
```

#### Ubuntu
```bash
# 필수 패키지 설치
apt-get update
apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release

# Docker GPG 키 추가
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# 저장소 추가
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# containerd 설치
apt-get update
apt-get install -y containerd.io

# 설정
mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml

systemctl enable containerd
systemctl start containerd
```

## 📦 쿠버네티스 패키지 설치

### CentOS/RHEL
```bash
# 저장소 추가
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

# 패키지 설치
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

# kubelet 활성화
systemctl enable kubelet
```

### Ubuntu
```bash
# GPG 키 추가
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

# 저장소 추가
cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

# 패키지 설치
apt-get update
apt-get install -y kubelet kubeadm kubectl

# 자동 업데이트 방지
apt-mark hold kubelet kubeadm kubectl

# kubelet 활성화
systemctl enable kubelet
```

## 🚀 설치 전략별 가이드

### 🎯 kubeadm 기반 설치 (권장)

**장점**:
- 공식 지원 도구
- 상대적으로 간단한 설정
- 광범위한 문서화
- 업그레이드 지원

**단점**:
- 초기 설정 복잡도
- 로드밸런서 별도 구성 필요

**적용 사례**: 대부분의 온프렘 환경

### 🛠️ Kubespray (Ansible) 기반

**장점**:
- 완전 자동화
- 다양한 옵션 지원
- 대규모 배포 적합

**단점**:
- Ansible 지식 필요
- 디버깅 복잡

**적용 사례**: 대규모 환경, 자동화 중시

### 🖥️ Rancher 기반

**장점**:
- 웹 UI 제공
- 관리 편의성
- 멀티 클러스터 지원

**단점**:
- 추가 레이어
- 벤더 종속성

**적용 사례**: 관리 편의성 중시

## 🔍 설치 후 검증

### 클러스터 상태 확인
```bash
# 노드 확인
kubectl get nodes

# 시스템 Pod 확인
kubectl get pods -n kube-system

# 컴포넌트 상태 확인
kubectl get componentstatuses
```

### 기본 테스트
```bash
# 테스트 Pod 생성
kubectl run test-pod --image=nginx --restart=Never

# Pod 상태 확인
kubectl get pod test-pod

# 로그 확인
kubectl logs test-pod

# 정리
kubectl delete pod test-pod
```

## 🚨 실전 트러블슈팅

### 일반적인 문제들

#### 1. kubelet이 시작되지 않음
```bash
# 로그 확인
journalctl -xeu kubelet

# 흔한 원인
- swap이 활성화되어 있음
- 컨테이너 런타임 문제
- cgroup 드라이버 불일치
```

#### 2. Pod가 Pending 상태
```bash
# Pod 상세 정보 확인
kubectl describe pod <pod-name>

# 흔한 원인
- 리소스 부족
- 노드 스케줄링 제약
- PV 마운트 실패
```

#### 3. 네트워크 통신 문제
```bash
# CNI 플러그인 확인
kubectl get pods -n kube-system | grep -E "calico|flannel|weave"

# 네트워크 정책 확인
kubectl get networkpolicies --all-namespaces
```

## 💡 실전 운영 팁

### 🔧 성능 최적화
1. **SSD 사용**: etcd와 containerd용
2. **전용 네트워크**: 클러스터 내부 통신용
3. **리소스 예약**: 시스템 컴포넌트용

### 🛡️ 보안 강화
1. **최소 권한 원칙**: RBAC 설정
2. **네트워크 분리**: 클러스터 전용 VLAN
3. **정기 업데이트**: 보안 패치 적용

### 📊 모니터링 준비
1. **메트릭 수집**: Prometheus 준비
2. **로그 수집**: 중앙 집중식 로깅
3. **알림 설정**: 장애 대응 체계

## 🔗 다음 단계

설치가 완료되면 다음 문서들을 참고하세요:

- [[02-Installation/kubeadm으로 클러스터 구축|kubeadm으로 클러스터 구축]]
- [[02-Installation/고가용성 클러스터 구성|고가용성 클러스터 구성]]
- [[03-Cluster-Management/노드 관리|노드 관리]]
- [[08-Monitoring/Prometheus 스택 구축|모니터링 설정]]

---

> 💡 **실전 경험**: 온프렘 설치의 성공 요소는 사전 계획입니다. 특히 네트워크와 스토리지 설계에 충분한 시간을 투자하세요.

태그: #installation #onprem #strategy #kubeadm